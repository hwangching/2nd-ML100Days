{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 請比較使用 l1, l2, l1_l2 及不同比例下的訓練結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import itertools\n",
    "\n",
    "# 設定 GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 從 Keras 的內建功能中，取得 train 與 test 資料集\n",
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# 資料前處理 - X 標準化\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# 資料前處理 -Y 轉成 onehot\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l1_l2\n",
    "\n",
    "\"\"\"\n",
    "建立神經網路\n",
    "\"\"\"\n",
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128], l1_ratio=0.0, l2_ratio=0.0):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1), \n",
    "                                   kernel_regularizer=l1_l2(l1=l1_ratio, l2=l2_ratio))(input_layer)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1),\n",
    "                                   kernel_regularizer=l1_l2(l1=l1_ratio, l2=l2_ratio))(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 超參數設定\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "MOMENTUM = 0.95\n",
    "L1_EXP = [1e-2, 1e-4, 1e-8, 1e-12, 0.0]\n",
    "L2_EXP = [1e-2, 1e-4, 1e-8, 1e-12, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with L1 = 0.010000, L2 = 0.010000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 197.8613 - acc: 0.2285 - val_loss: 35.9860 - val_acc: 0.2298\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 15.9300 - acc: 0.1111 - val_loss: 5.1332 - val_acc: 0.1000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 3.2123 - acc: 0.1000 - val_loss: 2.4720 - val_acc: 0.1000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 2.4632 - acc: 0.0990 - val_loss: 2.4623 - val_acc: 0.1000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 2.4624 - acc: 0.0995 - val_loss: 2.4622 - val_acc: 0.1000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 2.4624 - acc: 0.0984 - val_loss: 2.4623 - val_acc: 0.1000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 2.4623 - acc: 0.0989 - val_loss: 2.4623 - val_acc: 0.1000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 2.4623 - acc: 0.0979 - val_loss: 2.4623 - val_acc: 0.1000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 2.4623 - acc: 0.0962 - val_loss: 2.4621 - val_acc: 0.1000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 2.4622 - acc: 0.0984 - val_loss: 2.4620 - val_acc: 0.1000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 2.4622 - acc: 0.0984 - val_loss: 2.4620 - val_acc: 0.1000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 2.4621 - acc: 0.0981 - val_loss: 2.4621 - val_acc: 0.1000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 2.4621 - acc: 0.0988 - val_loss: 2.4620 - val_acc: 0.1000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 2.4621 - acc: 0.0968 - val_loss: 2.4619 - val_acc: 0.1000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 2.4621 - acc: 0.0996 - val_loss: 2.4620 - val_acc: 0.1000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 2.4620 - acc: 0.0990 - val_loss: 2.4619 - val_acc: 0.1000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 2.4620 - acc: 0.0976 - val_loss: 2.4619 - val_acc: 0.1000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 2.4620 - acc: 0.0988 - val_loss: 2.4620 - val_acc: 0.1000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 2.4620 - acc: 0.0978 - val_loss: 2.4619 - val_acc: 0.1000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 2.4620 - acc: 0.0975 - val_loss: 2.4619 - val_acc: 0.1000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 2.4619 - acc: 0.0969 - val_loss: 2.4619 - val_acc: 0.1000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 2.4619 - acc: 0.0975 - val_loss: 2.4620 - val_acc: 0.1000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 2.4619 - acc: 0.0983 - val_loss: 2.4619 - val_acc: 0.1000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 2.4619 - acc: 0.0964 - val_loss: 2.4619 - val_acc: 0.1000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 2.4619 - acc: 0.0988 - val_loss: 2.4618 - val_acc: 0.1000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 2.4619 - acc: 0.0978 - val_loss: 2.4618 - val_acc: 0.1000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 2.4619 - acc: 0.0972 - val_loss: 2.4619 - val_acc: 0.1000\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 2.4619 - acc: 0.0966 - val_loss: 2.4619 - val_acc: 0.1000\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 2.4618 - acc: 0.0984 - val_loss: 2.4617 - val_acc: 0.1000\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 2.4618 - acc: 0.0955 - val_loss: 2.4617 - val_acc: 0.1000\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 2.4618 - acc: 0.0990 - val_loss: 2.4618 - val_acc: 0.1000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 2.4618 - acc: 0.0964 - val_loss: 2.4617 - val_acc: 0.1000\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 2.4617 - acc: 0.0987 - val_loss: 2.4618 - val_acc: 0.1000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 2.4617 - acc: 0.0977 - val_loss: 2.4618 - val_acc: 0.1000\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 2.4617 - acc: 0.0975 - val_loss: 2.4616 - val_acc: 0.1000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 2.4617 - acc: 0.0977 - val_loss: 2.4616 - val_acc: 0.1000\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 2.4617 - acc: 0.0976 - val_loss: 2.4617 - val_acc: 0.1000\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 2.4616 - acc: 0.0988 - val_loss: 2.4617 - val_acc: 0.1000\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 2.4616 - acc: 0.0998 - val_loss: 2.4616 - val_acc: 0.1000\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 2.4616 - acc: 0.0981 - val_loss: 2.4615 - val_acc: 0.1000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 2.4616 - acc: 0.0971 - val_loss: 2.4615 - val_acc: 0.1000\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 2.4616 - acc: 0.0988 - val_loss: 2.4616 - val_acc: 0.1000\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 2.4615 - acc: 0.0974 - val_loss: 2.4616 - val_acc: 0.1000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 2.4615 - acc: 0.0981 - val_loss: 2.4614 - val_acc: 0.1000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 2.4615 - acc: 0.0964 - val_loss: 2.4613 - val_acc: 0.1000\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 2.4615 - acc: 0.0985 - val_loss: 2.4614 - val_acc: 0.1000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 2.4615 - acc: 0.0976 - val_loss: 2.4614 - val_acc: 0.1000\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 2.4614 - acc: 0.0977 - val_loss: 2.4614 - val_acc: 0.1000\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 2.4614 - acc: 0.0965 - val_loss: 2.4614 - val_acc: 0.1000\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 2.4614 - acc: 0.0958 - val_loss: 2.4613 - val_acc: 0.1000\n",
      "Experiment with L1 = 0.010000, L2 = 0.000100\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 198.8074 - acc: 0.2322 - val_loss: 41.1290 - val_acc: 0.2547\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 19.1220 - acc: 0.1173 - val_loss: 7.2877 - val_acc: 0.1000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 4.1123 - acc: 0.0997 - val_loss: 2.6472 - val_acc: 0.1000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 2.4857 - acc: 0.0993 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 2.4626 - acc: 0.0984 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 2.4626 - acc: 0.0975 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 2.4626 - acc: 0.0986 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 2.4626 - acc: 0.0989 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 2.4626 - acc: 0.0963 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 2.4626 - acc: 0.0969 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 2.4626 - acc: 0.0968 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 2.4626 - acc: 0.0981 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 2.4626 - acc: 0.0990 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 2.4626 - acc: 0.0988 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 2.4626 - acc: 0.0990 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 2.4626 - acc: 0.0971 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 2.4626 - acc: 0.0973 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 2.4626 - acc: 0.0955 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 2.4626 - acc: 0.0985 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 2.4626 - acc: 0.0971 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 2.4626 - acc: 0.0970 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 2.4626 - acc: 0.0979 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 2.4626 - acc: 0.0963 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 2.4626 - acc: 0.0984 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 2.4626 - acc: 0.0981 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 2.4626 - acc: 0.0967 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 2.4626 - acc: 0.0975 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 2.4626 - acc: 0.0981 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 2.4626 - acc: 0.0969 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 2.4626 - acc: 0.0981 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 2.4626 - acc: 0.0991 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 2.4626 - acc: 0.0977 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 2.4626 - acc: 0.0981 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 2.4626 - acc: 0.0975 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 2.4626 - acc: 0.0974 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 2.4626 - acc: 0.0958 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 2.4626 - acc: 0.0970 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 2.4626 - acc: 0.0965 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 2.4626 - acc: 0.0997 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 2.4626 - acc: 0.0969 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Experiment with L1 = 0.010000, L2 = 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 198.5931 - acc: 0.2449 - val_loss: 41.1193 - val_acc: 0.2566\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 19.1244 - acc: 0.1164 - val_loss: 7.3040 - val_acc: 0.1000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 4.1155 - acc: 0.0986 - val_loss: 2.6487 - val_acc: 0.1000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 2.4863 - acc: 0.0962 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 2.4626 - acc: 0.0979 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 2.4626 - acc: 0.0987 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 2.4626 - acc: 0.0955 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 2.4626 - acc: 0.0996 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 2.4626 - acc: 0.0973 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 2.4626 - acc: 0.0985 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 2.4626 - acc: 0.0970 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 2.4626 - acc: 0.0974 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 2.4626 - acc: 0.0981 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 2.4626 - acc: 0.0976 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 2.4626 - acc: 0.0994 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 2.4626 - acc: 0.0981 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 2.4626 - acc: 0.0974 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 2.4626 - acc: 0.0999 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 2.4626 - acc: 0.0985 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 2.4626 - acc: 0.0965 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 2.4626 - acc: 0.0991 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 2.4626 - acc: 0.0973 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 2.4626 - acc: 0.1000 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 2.4626 - acc: 0.0969 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 2.4626 - acc: 0.0985 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 2.4626 - acc: 0.0965 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 2.4626 - acc: 0.0971 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 2.4626 - acc: 0.0994 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 2.4626 - acc: 0.0984 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 2.4626 - acc: 0.0961 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 2.4626 - acc: 0.0988 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 2.4626 - acc: 0.0993 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 2.4626 - acc: 0.0970 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 2.4626 - acc: 0.0984 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 2.4626 - acc: 0.0977 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 2.4626 - acc: 0.1004 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 2.4626 - acc: 0.0968 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 2.4626 - acc: 0.0974 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 2.4626 - acc: 0.0960 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Experiment with L1 = 0.010000, L2 = 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 198.6147 - acc: 0.2447 - val_loss: 41.0872 - val_acc: 0.2763\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 8s 157us/step - loss: 19.0978 - acc: 0.1214 - val_loss: 7.2845 - val_acc: 0.1000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 4.1132 - acc: 0.0991 - val_loss: 2.6512 - val_acc: 0.1000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 2.4866 - acc: 0.0987 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 2.4626 - acc: 0.0987 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 2.4626 - acc: 0.0976 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 2.4626 - acc: 0.0973 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 2.4626 - acc: 0.0968 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 2.4626 - acc: 0.0970 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 2.4626 - acc: 0.0989 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 2.4626 - acc: 0.0976 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 2.4626 - acc: 0.0968 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 2.4626 - acc: 0.0954 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 2.4626 - acc: 0.0987 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 2.4626 - acc: 0.0988 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 2.4626 - acc: 0.0971 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 2.4626 - acc: 0.0976 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 2.4626 - acc: 0.0990 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 2.4626 - acc: 0.0972 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 2.4626 - acc: 0.0988 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 2.4626 - acc: 0.0991 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 2.4626 - acc: 0.0952 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 2.4626 - acc: 0.0971 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 2.4626 - acc: 0.0977 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 2.4626 - acc: 0.0987 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 2.4626 - acc: 0.0972 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 2.4626 - acc: 0.0976 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 2.4626 - acc: 0.0984 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 2.4626 - acc: 0.0987 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 2.4626 - acc: 0.0989 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 2.4626 - acc: 0.0987 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 2.4626 - acc: 0.0990 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 2.4626 - acc: 0.0992 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 2.4626 - acc: 0.0976 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 2.4626 - acc: 0.0981 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 2.4626 - acc: 0.0988 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 2.4626 - acc: 0.0967 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 2.4626 - acc: 0.0965 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 2.4626 - acc: 0.0969 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 2.4626 - acc: 0.0970 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 2.4626 - acc: 0.0979 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 2.4626 - acc: 0.0970 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 2.4626 - acc: 0.0983 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Experiment with L1 = 0.010000, L2 = 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 198.6661 - acc: 0.2234 - val_loss: 41.0782 - val_acc: 0.2445\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 19.0958 - acc: 0.1165 - val_loss: 7.2979 - val_acc: 0.1000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 4.1168 - acc: 0.0990 - val_loss: 2.6470 - val_acc: 0.1000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 2.4856 - acc: 0.0979 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 2.4626 - acc: 0.0967 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 2.4626 - acc: 0.0985 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 2.4626 - acc: 0.0973 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 2.4626 - acc: 0.0965 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 2.4626 - acc: 0.0968 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 2.4626 - acc: 0.0989 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 2.4626 - acc: 0.0976 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 2.4626 - acc: 0.0975 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 2.4626 - acc: 0.0975 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 2.4626 - acc: 0.0955 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 2.4626 - acc: 0.0961 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 2.4626 - acc: 0.0957 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 2.4626 - acc: 0.0989 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 2.4626 - acc: 0.0979 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 2.4626 - acc: 0.0970 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 2.4626 - acc: 0.0984 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 2.4626 - acc: 0.0987 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 2.4626 - acc: 0.1000 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 2.4626 - acc: 0.0977 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 2.4626 - acc: 0.0977 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 2.4626 - acc: 0.0976 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 2.4626 - acc: 0.0962 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 2.4626 - acc: 0.0967 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 2.4626 - acc: 0.0963 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 2.4626 - acc: 0.0986 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 2.4626 - acc: 0.0984 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 2.4626 - acc: 0.0972 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 2.4626 - acc: 0.0973 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 2.4626 - acc: 0.0964 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 2.4626 - acc: 0.0981 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 2.4626 - acc: 0.0991 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 2.4626 - acc: 0.0988 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 2.4626 - acc: 0.0972 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Experiment with L1 = 0.000100, L2 = 0.010000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 18.7896 - acc: 0.2784 - val_loss: 17.3405 - val_acc: 0.3477\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 16.1309 - acc: 0.3598 - val_loss: 14.9654 - val_acc: 0.3790\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 13.9475 - acc: 0.3815 - val_loss: 12.9766 - val_acc: 0.3819\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 7s 145us/step - loss: 12.1017 - acc: 0.3958 - val_loss: 11.2722 - val_acc: 0.3971\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 10.5313 - acc: 0.4043 - val_loss: 9.8158 - val_acc: 0.4105\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 9.1932 - acc: 0.4106 - val_loss: 8.5867 - val_acc: 0.4150\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 8.0552 - acc: 0.4162 - val_loss: 7.5439 - val_acc: 0.4187\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 7.0854 - acc: 0.4241 - val_loss: 6.6425 - val_acc: 0.4284\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 6.2591 - acc: 0.4267 - val_loss: 5.8925 - val_acc: 0.4239\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 5.5557 - acc: 0.4309 - val_loss: 5.2341 - val_acc: 0.4356\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 4.9577 - acc: 0.4338 - val_loss: 4.6905 - val_acc: 0.4336\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 4.4488 - acc: 0.4362 - val_loss: 4.2303 - val_acc: 0.4322\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 4.0168 - acc: 0.4385 - val_loss: 3.8224 - val_acc: 0.4401\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 3.6483 - acc: 0.4425 - val_loss: 3.4831 - val_acc: 0.4423\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 3.3380 - acc: 0.4435 - val_loss: 3.2080 - val_acc: 0.4375\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 3.0766 - acc: 0.4461 - val_loss: 2.9622 - val_acc: 0.4441\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 2.8559 - acc: 0.4483 - val_loss: 2.7649 - val_acc: 0.4439\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 2.6711 - acc: 0.4478 - val_loss: 2.6010 - val_acc: 0.4475\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 2.5178 - acc: 0.4511 - val_loss: 2.4593 - val_acc: 0.4401\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 2.3889 - acc: 0.4512 - val_loss: 2.3832 - val_acc: 0.4192\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 2.2847 - acc: 0.4523 - val_loss: 2.2476 - val_acc: 0.4423\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 2.1999 - acc: 0.4503 - val_loss: 2.1712 - val_acc: 0.4477\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 2.1274 - acc: 0.4517 - val_loss: 2.1326 - val_acc: 0.4371\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 2.0709 - acc: 0.4547 - val_loss: 2.0503 - val_acc: 0.4540\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 2.0258 - acc: 0.4533 - val_loss: 2.0071 - val_acc: 0.4545\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.9874 - acc: 0.4539 - val_loss: 2.0319 - val_acc: 0.4313\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 1.9599 - acc: 0.4539 - val_loss: 1.9604 - val_acc: 0.4456\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.9323 - acc: 0.4570 - val_loss: 1.9632 - val_acc: 0.4407\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.9118 - acc: 0.4566 - val_loss: 1.9299 - val_acc: 0.4437\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.8936 - acc: 0.4600 - val_loss: 1.9209 - val_acc: 0.4437\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.8800 - acc: 0.4590 - val_loss: 1.8739 - val_acc: 0.4605\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.8646 - acc: 0.4620 - val_loss: 1.8798 - val_acc: 0.4450\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.8516 - acc: 0.4618 - val_loss: 1.8565 - val_acc: 0.4576\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.8413 - acc: 0.4630 - val_loss: 1.8579 - val_acc: 0.4606\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.8318 - acc: 0.4655 - val_loss: 1.8519 - val_acc: 0.4568\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.8229 - acc: 0.4649 - val_loss: 1.8384 - val_acc: 0.4552\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.8161 - acc: 0.4668 - val_loss: 1.8462 - val_acc: 0.4605\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.8068 - acc: 0.4710 - val_loss: 1.8578 - val_acc: 0.4500\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.8003 - acc: 0.4701 - val_loss: 1.8394 - val_acc: 0.4535\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.7938 - acc: 0.4735 - val_loss: 1.8291 - val_acc: 0.4561\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.7894 - acc: 0.4731 - val_loss: 1.8045 - val_acc: 0.4676\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.7832 - acc: 0.4723 - val_loss: 1.8533 - val_acc: 0.4421\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.7782 - acc: 0.4751 - val_loss: 1.7993 - val_acc: 0.4673\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.7744 - acc: 0.4752 - val_loss: 1.7886 - val_acc: 0.4772\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.7678 - acc: 0.4775 - val_loss: 1.7811 - val_acc: 0.4693\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.7664 - acc: 0.4763 - val_loss: 1.8383 - val_acc: 0.4515\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.7602 - acc: 0.4785 - val_loss: 1.7817 - val_acc: 0.4673\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.7570 - acc: 0.4805 - val_loss: 1.8625 - val_acc: 0.4285\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.7533 - acc: 0.4806 - val_loss: 1.7847 - val_acc: 0.4689\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.7508 - acc: 0.4810 - val_loss: 1.7918 - val_acc: 0.4655\n",
      "Experiment with L1 = 0.000100, L2 = 0.000100\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 6.1181 - acc: 0.2881 - val_loss: 5.9271 - val_acc: 0.3560\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 5.8396 - acc: 0.3680 - val_loss: 5.7568 - val_acc: 0.3931\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 5.6891 - acc: 0.3965 - val_loss: 5.6217 - val_acc: 0.4113\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 5.5612 - acc: 0.4186 - val_loss: 5.5034 - val_acc: 0.4300\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 5.4452 - acc: 0.4364 - val_loss: 5.4069 - val_acc: 0.4388\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 5.3384 - acc: 0.4476 - val_loss: 5.3045 - val_acc: 0.4509\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 5.2401 - acc: 0.4592 - val_loss: 5.2106 - val_acc: 0.4573\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 5.1446 - acc: 0.4700 - val_loss: 5.1234 - val_acc: 0.4623\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 5.0561 - acc: 0.4755 - val_loss: 5.0418 - val_acc: 0.4658\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 4.9659 - acc: 0.4859 - val_loss: 4.9529 - val_acc: 0.4741\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 4.8800 - acc: 0.4927 - val_loss: 4.8730 - val_acc: 0.4816\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 4.7958 - acc: 0.5002 - val_loss: 4.8005 - val_acc: 0.4885\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 4.7137 - acc: 0.5080 - val_loss: 4.7318 - val_acc: 0.4843\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 4.6353 - acc: 0.5118 - val_loss: 4.6827 - val_acc: 0.4790\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 4.5590 - acc: 0.5165 - val_loss: 4.5956 - val_acc: 0.4847\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 4.4811 - acc: 0.5233 - val_loss: 4.5115 - val_acc: 0.4919\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 4.4040 - acc: 0.5282 - val_loss: 4.4374 - val_acc: 0.5012\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 4.3312 - acc: 0.5344 - val_loss: 4.3933 - val_acc: 0.4950\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 4.2591 - acc: 0.5382 - val_loss: 4.2980 - val_acc: 0.5058\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 4.1877 - acc: 0.5442 - val_loss: 4.2353 - val_acc: 0.5073\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 4.1208 - acc: 0.5477 - val_loss: 4.1762 - val_acc: 0.5117\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 4.0520 - acc: 0.5535 - val_loss: 4.1678 - val_acc: 0.5007\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 3.9826 - acc: 0.5592 - val_loss: 4.0558 - val_acc: 0.5171\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 3.9191 - acc: 0.5606 - val_loss: 4.0084 - val_acc: 0.5162\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 3.8524 - acc: 0.5660 - val_loss: 3.9632 - val_acc: 0.5067\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 3.7910 - acc: 0.5685 - val_loss: 3.8815 - val_acc: 0.5213\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 3.7280 - acc: 0.5739 - val_loss: 3.8562 - val_acc: 0.5121\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 3.6697 - acc: 0.5748 - val_loss: 3.7662 - val_acc: 0.5253\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 3.6077 - acc: 0.5802 - val_loss: 3.8451 - val_acc: 0.4858\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 3.5495 - acc: 0.5813 - val_loss: 3.6953 - val_acc: 0.5175\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 3.4905 - acc: 0.5858 - val_loss: 3.6475 - val_acc: 0.5119\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 3.4370 - acc: 0.5888 - val_loss: 3.5759 - val_acc: 0.5239\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 3.3813 - acc: 0.5920 - val_loss: 3.5442 - val_acc: 0.5161\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 3.3258 - acc: 0.5943 - val_loss: 3.5265 - val_acc: 0.5169\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 3.2748 - acc: 0.5955 - val_loss: 3.5115 - val_acc: 0.5128\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 3.2282 - acc: 0.5963 - val_loss: 3.4229 - val_acc: 0.5162\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 3.1714 - acc: 0.6017 - val_loss: 3.3621 - val_acc: 0.5212\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 3.1259 - acc: 0.6024 - val_loss: 3.3073 - val_acc: 0.5197\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 3.0718 - acc: 0.6067 - val_loss: 3.2721 - val_acc: 0.5181\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 3.0259 - acc: 0.6095 - val_loss: 3.3012 - val_acc: 0.5024\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 2.9831 - acc: 0.6094 - val_loss: 3.2913 - val_acc: 0.4997\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 2.9361 - acc: 0.6134 - val_loss: 3.2054 - val_acc: 0.5112\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 2.8877 - acc: 0.6160 - val_loss: 3.1463 - val_acc: 0.5188\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 2.8457 - acc: 0.6172 - val_loss: 3.1004 - val_acc: 0.5153\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 2.8047 - acc: 0.6180 - val_loss: 3.0774 - val_acc: 0.5197\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 2.7675 - acc: 0.6171 - val_loss: 2.9804 - val_acc: 0.5316\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 2.7248 - acc: 0.6206 - val_loss: 2.9523 - val_acc: 0.5312\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 2.6870 - acc: 0.6211 - val_loss: 2.9282 - val_acc: 0.5300\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 2.6489 - acc: 0.6226 - val_loss: 2.9333 - val_acc: 0.5166\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 2.6055 - acc: 0.6271 - val_loss: 2.9169 - val_acc: 0.5128\n",
      "Experiment with L1 = 0.000100, L2 = 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 6.0270 - acc: 0.2658 - val_loss: 5.8235 - val_acc: 0.3379\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 5.7319 - acc: 0.3622 - val_loss: 5.6547 - val_acc: 0.3771\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 5.5867 - acc: 0.3894 - val_loss: 5.5229 - val_acc: 0.4027\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 5.4668 - acc: 0.4084 - val_loss: 5.4125 - val_acc: 0.4150\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 5.3582 - acc: 0.4259 - val_loss: 5.3304 - val_acc: 0.4210\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 5s 105us/step - loss: 5.2580 - acc: 0.4383 - val_loss: 5.2408 - val_acc: 0.4311\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 5.1622 - acc: 0.4514 - val_loss: 5.1274 - val_acc: 0.4501\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 5.0706 - acc: 0.4595 - val_loss: 5.0409 - val_acc: 0.4523\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 4.9822 - acc: 0.4713 - val_loss: 4.9775 - val_acc: 0.4553\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 4.8991 - acc: 0.4781 - val_loss: 4.8777 - val_acc: 0.4730\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 4.8162 - acc: 0.4863 - val_loss: 4.8406 - val_acc: 0.4599\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 4.7349 - acc: 0.4952 - val_loss: 4.7541 - val_acc: 0.4703\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 4.6560 - acc: 0.5015 - val_loss: 4.6619 - val_acc: 0.4792\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 4.5817 - acc: 0.5066 - val_loss: 4.6032 - val_acc: 0.4775\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 4.5068 - acc: 0.5123 - val_loss: 4.5244 - val_acc: 0.4909\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 4.4329 - acc: 0.5179 - val_loss: 4.4815 - val_acc: 0.4865\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 4.3617 - acc: 0.5245 - val_loss: 4.3931 - val_acc: 0.4996\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 4.2904 - acc: 0.5314 - val_loss: 4.3381 - val_acc: 0.4997\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 4.2217 - acc: 0.5342 - val_loss: 4.2924 - val_acc: 0.4890\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 4.1564 - acc: 0.5399 - val_loss: 4.2107 - val_acc: 0.5049\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 4.0906 - acc: 0.5424 - val_loss: 4.1817 - val_acc: 0.4901\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 4.0295 - acc: 0.5479 - val_loss: 4.0900 - val_acc: 0.5086\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 3.9630 - acc: 0.5507 - val_loss: 4.0434 - val_acc: 0.5096\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 3.8994 - acc: 0.5570 - val_loss: 3.9863 - val_acc: 0.5126\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 3.8398 - acc: 0.5613 - val_loss: 3.9273 - val_acc: 0.5148\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.7813 - acc: 0.5626 - val_loss: 3.9893 - val_acc: 0.4743\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 3.7259 - acc: 0.5654 - val_loss: 3.9049 - val_acc: 0.4940\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 3.6664 - acc: 0.5690 - val_loss: 3.7700 - val_acc: 0.5232\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 3.6095 - acc: 0.5706 - val_loss: 3.7148 - val_acc: 0.5260\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 3.5539 - acc: 0.5759 - val_loss: 3.7182 - val_acc: 0.5055\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 3.4972 - acc: 0.5782 - val_loss: 3.6407 - val_acc: 0.5138\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 3.4476 - acc: 0.5823 - val_loss: 3.7967 - val_acc: 0.4555\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 3.3960 - acc: 0.5829 - val_loss: 3.5151 - val_acc: 0.5344\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.3365 - acc: 0.5902 - val_loss: 3.6332 - val_acc: 0.4801\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 3.2891 - acc: 0.5899 - val_loss: 3.4533 - val_acc: 0.5237\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 3.2420 - acc: 0.5925 - val_loss: 3.4188 - val_acc: 0.5216\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 3.1890 - acc: 0.5985 - val_loss: 3.3812 - val_acc: 0.5140\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 3.1428 - acc: 0.5984 - val_loss: 3.3187 - val_acc: 0.5242\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 3.0947 - acc: 0.6029 - val_loss: 3.3689 - val_acc: 0.4980\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 3.0556 - acc: 0.6027 - val_loss: 3.2715 - val_acc: 0.5140\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 3.0063 - acc: 0.6054 - val_loss: 3.1809 - val_acc: 0.5370\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 2.9675 - acc: 0.6054 - val_loss: 3.1461 - val_acc: 0.5359\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 2.9200 - acc: 0.6093 - val_loss: 3.1184 - val_acc: 0.5325\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 2.8771 - acc: 0.6130 - val_loss: 3.0933 - val_acc: 0.5290\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 2.8360 - acc: 0.6154 - val_loss: 3.1691 - val_acc: 0.5014\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 2.7986 - acc: 0.6150 - val_loss: 3.0382 - val_acc: 0.5266\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 2.7580 - acc: 0.6166 - val_loss: 3.0187 - val_acc: 0.5241\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 2.7162 - acc: 0.6202 - val_loss: 3.0013 - val_acc: 0.5205\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 2.6761 - acc: 0.6227 - val_loss: 2.9076 - val_acc: 0.5344\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 2.6431 - acc: 0.6237 - val_loss: 2.9040 - val_acc: 0.5256\n",
      "Experiment with L1 = 0.000100, L2 = 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 6.0054 - acc: 0.2759 - val_loss: 5.8087 - val_acc: 0.3437\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 5.7224 - acc: 0.3653 - val_loss: 5.6504 - val_acc: 0.3634\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 5.5787 - acc: 0.3945 - val_loss: 5.5264 - val_acc: 0.3940\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 5.4567 - acc: 0.4135 - val_loss: 5.4039 - val_acc: 0.4250\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 5.3475 - acc: 0.4287 - val_loss: 5.2989 - val_acc: 0.4332\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 5.2441 - acc: 0.4452 - val_loss: 5.2016 - val_acc: 0.4450\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 5.1483 - acc: 0.4544 - val_loss: 5.1413 - val_acc: 0.4378\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 5.0572 - acc: 0.4648 - val_loss: 5.0346 - val_acc: 0.4615\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 4.9700 - acc: 0.4737 - val_loss: 4.9519 - val_acc: 0.4662\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 4.8847 - acc: 0.4833 - val_loss: 4.8788 - val_acc: 0.4741\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 4.8048 - acc: 0.4905 - val_loss: 4.7936 - val_acc: 0.4819\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 4.7236 - acc: 0.4988 - val_loss: 4.7397 - val_acc: 0.4767\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 4.6468 - acc: 0.5041 - val_loss: 4.6576 - val_acc: 0.4816\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 4.5708 - acc: 0.5108 - val_loss: 4.5804 - val_acc: 0.4973\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 4.4973 - acc: 0.5156 - val_loss: 4.5428 - val_acc: 0.4915\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 4.4245 - acc: 0.5210 - val_loss: 4.4524 - val_acc: 0.5011\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 4.3554 - acc: 0.5263 - val_loss: 4.4064 - val_acc: 0.4944\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 4.2824 - acc: 0.5309 - val_loss: 4.3573 - val_acc: 0.4916\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 4.2166 - acc: 0.5374 - val_loss: 4.2627 - val_acc: 0.5082\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 4.1513 - acc: 0.5408 - val_loss: 4.2022 - val_acc: 0.5070\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 4.0852 - acc: 0.5456 - val_loss: 4.1638 - val_acc: 0.5062\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 4.0209 - acc: 0.5498 - val_loss: 4.0854 - val_acc: 0.5130\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 3.9569 - acc: 0.5555 - val_loss: 4.0358 - val_acc: 0.5142\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 3.8958 - acc: 0.5592 - val_loss: 3.9707 - val_acc: 0.5190\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 3.8358 - acc: 0.5620 - val_loss: 3.9230 - val_acc: 0.5203\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 3.7753 - acc: 0.5667 - val_loss: 3.8999 - val_acc: 0.5113\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.7169 - acc: 0.5696 - val_loss: 3.8785 - val_acc: 0.5037\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.6592 - acc: 0.5734 - val_loss: 3.7686 - val_acc: 0.5253\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.6043 - acc: 0.5760 - val_loss: 3.7280 - val_acc: 0.5160\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.5471 - acc: 0.5802 - val_loss: 3.7838 - val_acc: 0.4938\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 3.4928 - acc: 0.5827 - val_loss: 3.6608 - val_acc: 0.5128\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 3.4414 - acc: 0.5855 - val_loss: 3.5723 - val_acc: 0.5267\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 3.3848 - acc: 0.5898 - val_loss: 3.5936 - val_acc: 0.5015\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.3349 - acc: 0.5912 - val_loss: 3.5323 - val_acc: 0.5166\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 3.2855 - acc: 0.5940 - val_loss: 3.5793 - val_acc: 0.4932\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.2374 - acc: 0.5967 - val_loss: 3.4281 - val_acc: 0.5142\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 3.1871 - acc: 0.6011 - val_loss: 3.3859 - val_acc: 0.5187\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 3.1387 - acc: 0.6032 - val_loss: 3.3310 - val_acc: 0.5261\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 3.0900 - acc: 0.6062 - val_loss: 3.3133 - val_acc: 0.5216\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 3.0498 - acc: 0.6050 - val_loss: 3.2422 - val_acc: 0.5290\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 3.0007 - acc: 0.6116 - val_loss: 3.2841 - val_acc: 0.5134\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 2.9562 - acc: 0.6135 - val_loss: 3.2516 - val_acc: 0.5091\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 2.9152 - acc: 0.6147 - val_loss: 3.1753 - val_acc: 0.5166\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 2.8797 - acc: 0.6149 - val_loss: 3.1313 - val_acc: 0.5197\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 2.8330 - acc: 0.6164 - val_loss: 3.0686 - val_acc: 0.5301\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 2.7901 - acc: 0.6194 - val_loss: 3.0343 - val_acc: 0.5277\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 2.7468 - acc: 0.6228 - val_loss: 3.2429 - val_acc: 0.4766\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 2.7183 - acc: 0.6207 - val_loss: 2.9902 - val_acc: 0.5173\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 2.6787 - acc: 0.6233 - val_loss: 3.0184 - val_acc: 0.5105\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 2.6432 - acc: 0.6260 - val_loss: 2.9188 - val_acc: 0.5251\n",
      "Experiment with L1 = 0.000100, L2 = 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 6.0006 - acc: 0.2767 - val_loss: 5.8111 - val_acc: 0.3406\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 5.7187 - acc: 0.3643 - val_loss: 5.6480 - val_acc: 0.3777\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 5.5767 - acc: 0.3922 - val_loss: 5.5161 - val_acc: 0.3992\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 5.4593 - acc: 0.4096 - val_loss: 5.4032 - val_acc: 0.4226\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 5.3522 - acc: 0.4265 - val_loss: 5.3046 - val_acc: 0.4266\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 5.2513 - acc: 0.4385 - val_loss: 5.2118 - val_acc: 0.4414\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 5.1572 - acc: 0.4525 - val_loss: 5.1213 - val_acc: 0.4475\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 4s 90us/step - loss: 5.0672 - acc: 0.4625 - val_loss: 5.0532 - val_acc: 0.4522\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 4.9797 - acc: 0.4691 - val_loss: 4.9552 - val_acc: 0.4617\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 4.8950 - acc: 0.4775 - val_loss: 4.8828 - val_acc: 0.4641\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 4.8131 - acc: 0.4847 - val_loss: 4.8183 - val_acc: 0.4703\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 4.7319 - acc: 0.4929 - val_loss: 4.7430 - val_acc: 0.4744\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 4.6530 - acc: 0.5007 - val_loss: 4.6717 - val_acc: 0.4756\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 4.5766 - acc: 0.5064 - val_loss: 4.6000 - val_acc: 0.4875\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 4.5042 - acc: 0.5122 - val_loss: 4.5236 - val_acc: 0.4936\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 4.4315 - acc: 0.5170 - val_loss: 4.4586 - val_acc: 0.4941\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 4.3593 - acc: 0.5231 - val_loss: 4.3895 - val_acc: 0.4956\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 4.2908 - acc: 0.5285 - val_loss: 4.3286 - val_acc: 0.5039\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 4.2220 - acc: 0.5351 - val_loss: 4.2779 - val_acc: 0.5044\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 4.1535 - acc: 0.5387 - val_loss: 4.2473 - val_acc: 0.4956\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 4.0891 - acc: 0.5435 - val_loss: 4.1532 - val_acc: 0.5091\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 4.0231 - acc: 0.5457 - val_loss: 4.0881 - val_acc: 0.5151\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 3.9613 - acc: 0.5533 - val_loss: 4.0926 - val_acc: 0.4934\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 3.9003 - acc: 0.5560 - val_loss: 3.9966 - val_acc: 0.5130\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 3.8394 - acc: 0.5607 - val_loss: 3.9809 - val_acc: 0.4877\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 3.7795 - acc: 0.5616 - val_loss: 3.8890 - val_acc: 0.5120\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 3.7188 - acc: 0.5670 - val_loss: 3.8304 - val_acc: 0.5180\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 3.6614 - acc: 0.5707 - val_loss: 3.8263 - val_acc: 0.5002\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 3.6072 - acc: 0.5732 - val_loss: 3.7364 - val_acc: 0.5111\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 3.5482 - acc: 0.5787 - val_loss: 3.7633 - val_acc: 0.4988\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 3.4942 - acc: 0.5791 - val_loss: 3.6404 - val_acc: 0.5211\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 3.4420 - acc: 0.5830 - val_loss: 3.6134 - val_acc: 0.5137\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 3.3888 - acc: 0.5860 - val_loss: 3.5886 - val_acc: 0.5114\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 3.3373 - acc: 0.5866 - val_loss: 3.5362 - val_acc: 0.5107\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 3.2867 - acc: 0.5914 - val_loss: 3.4704 - val_acc: 0.5202\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 3.2343 - acc: 0.5950 - val_loss: 3.5018 - val_acc: 0.5023\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 3.1867 - acc: 0.5946 - val_loss: 3.3482 - val_acc: 0.5371\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 3.1413 - acc: 0.5998 - val_loss: 3.3265 - val_acc: 0.5292\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 3.0941 - acc: 0.6010 - val_loss: 3.3516 - val_acc: 0.5127\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 3.0514 - acc: 0.6018 - val_loss: 3.2222 - val_acc: 0.5380\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 3.0017 - acc: 0.6058 - val_loss: 3.2487 - val_acc: 0.5189\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 2.9584 - acc: 0.6091 - val_loss: 3.2373 - val_acc: 0.5125\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 2.9155 - acc: 0.6097 - val_loss: 3.1260 - val_acc: 0.5375\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 2.8748 - acc: 0.6118 - val_loss: 3.0785 - val_acc: 0.5299\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 2.8329 - acc: 0.6138 - val_loss: 3.0688 - val_acc: 0.5256\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 2.7977 - acc: 0.6113 - val_loss: 3.0404 - val_acc: 0.5226\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 2.7560 - acc: 0.6177 - val_loss: 3.0068 - val_acc: 0.5339\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 2.7245 - acc: 0.6170 - val_loss: 2.9512 - val_acc: 0.5354\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 2.6768 - acc: 0.6206 - val_loss: 2.9333 - val_acc: 0.5256\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 2.6431 - acc: 0.6231 - val_loss: 2.9347 - val_acc: 0.5207\n",
      "Experiment with L1 = 0.000000, L2 = 0.010000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 15.0880 - acc: 0.2681 - val_loss: 13.9539 - val_acc: 0.3457\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 13.0233 - acc: 0.3564 - val_loss: 12.1295 - val_acc: 0.3764\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 11.3477 - acc: 0.3811 - val_loss: 10.5973 - val_acc: 0.3918\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 9.9348 - acc: 0.3954 - val_loss: 9.2964 - val_acc: 0.3994\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 8.7345 - acc: 0.4053 - val_loss: 8.1912 - val_acc: 0.4117\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 7.7133 - acc: 0.4127 - val_loss: 7.2501 - val_acc: 0.4172\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 6.8424 - acc: 0.4166 - val_loss: 6.4508 - val_acc: 0.4159\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 6.0983 - acc: 0.4238 - val_loss: 5.7595 - val_acc: 0.4283\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 5.4621 - acc: 0.4295 - val_loss: 5.1754 - val_acc: 0.4316\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 4.9183 - acc: 0.4354 - val_loss: 4.6751 - val_acc: 0.4331\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 4.4529 - acc: 0.4403 - val_loss: 4.2484 - val_acc: 0.4391\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 4.0548 - acc: 0.4453 - val_loss: 3.8770 - val_acc: 0.4405\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 3.7151 - acc: 0.4484 - val_loss: 3.5672 - val_acc: 0.4430\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 3.4226 - acc: 0.4507 - val_loss: 3.3018 - val_acc: 0.4450\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 3.1716 - acc: 0.4568 - val_loss: 3.0617 - val_acc: 0.4560\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 2.9570 - acc: 0.4595 - val_loss: 2.9211 - val_acc: 0.4400\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 2.7742 - acc: 0.4618 - val_loss: 2.7104 - val_acc: 0.4559\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 2.6155 - acc: 0.4654 - val_loss: 2.5549 - val_acc: 0.4624\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 2.4802 - acc: 0.4691 - val_loss: 2.4399 - val_acc: 0.4602\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 2.3653 - acc: 0.4701 - val_loss: 2.3265 - val_acc: 0.4602\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 2.2647 - acc: 0.4726 - val_loss: 2.2403 - val_acc: 0.4677\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 2.1783 - acc: 0.4761 - val_loss: 2.1701 - val_acc: 0.4690\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 2.1045 - acc: 0.4783 - val_loss: 2.1277 - val_acc: 0.4490\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 2.0407 - acc: 0.4811 - val_loss: 2.0318 - val_acc: 0.4751\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.9843 - acc: 0.4846 - val_loss: 1.9774 - val_acc: 0.4761\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.9382 - acc: 0.4857 - val_loss: 1.9348 - val_acc: 0.4812\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.8953 - acc: 0.4877 - val_loss: 1.9078 - val_acc: 0.4697\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.8596 - acc: 0.4896 - val_loss: 1.8695 - val_acc: 0.4797\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.8287 - acc: 0.4913 - val_loss: 1.8533 - val_acc: 0.4801\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.8019 - acc: 0.4954 - val_loss: 1.8413 - val_acc: 0.4764\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.7776 - acc: 0.4946 - val_loss: 1.7947 - val_acc: 0.4839\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.7569 - acc: 0.4974 - val_loss: 1.8240 - val_acc: 0.4633\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.7402 - acc: 0.4997 - val_loss: 1.7627 - val_acc: 0.4893\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.7228 - acc: 0.5034 - val_loss: 1.7425 - val_acc: 0.4936\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.7072 - acc: 0.5054 - val_loss: 1.7370 - val_acc: 0.4907\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.6967 - acc: 0.5071 - val_loss: 1.7297 - val_acc: 0.4905\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.6861 - acc: 0.5075 - val_loss: 1.7445 - val_acc: 0.4847\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.6745 - acc: 0.5093 - val_loss: 1.7456 - val_acc: 0.4789\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.6678 - acc: 0.5115 - val_loss: 1.7190 - val_acc: 0.4885\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.6582 - acc: 0.5128 - val_loss: 1.7086 - val_acc: 0.4909\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.6524 - acc: 0.5127 - val_loss: 1.6944 - val_acc: 0.5015\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.6457 - acc: 0.5161 - val_loss: 1.7141 - val_acc: 0.4741\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.6383 - acc: 0.5179 - val_loss: 1.7110 - val_acc: 0.4817\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.6337 - acc: 0.5199 - val_loss: 1.6731 - val_acc: 0.4995\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.6315 - acc: 0.5169 - val_loss: 1.7047 - val_acc: 0.4854\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.6263 - acc: 0.5206 - val_loss: 1.6866 - val_acc: 0.4962\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.6216 - acc: 0.5201 - val_loss: 1.6680 - val_acc: 0.5011\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.6181 - acc: 0.5218 - val_loss: 1.6912 - val_acc: 0.4953\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.6159 - acc: 0.5220 - val_loss: 1.6642 - val_acc: 0.4973\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.6100 - acc: 0.5254 - val_loss: 1.6579 - val_acc: 0.5106\n",
      "Experiment with L1 = 0.000000, L2 = 0.000100\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 2.1644 - acc: 0.2780 - val_loss: 2.0010 - val_acc: 0.3470\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.9487 - acc: 0.3665 - val_loss: 1.9005 - val_acc: 0.3843\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.8648 - acc: 0.3969 - val_loss: 1.8380 - val_acc: 0.4078\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.8049 - acc: 0.4169 - val_loss: 1.7892 - val_acc: 0.4193\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.7574 - acc: 0.4329 - val_loss: 1.7369 - val_acc: 0.4357\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.7178 - acc: 0.4486 - val_loss: 1.7243 - val_acc: 0.4398\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.6870 - acc: 0.4574 - val_loss: 1.6880 - val_acc: 0.4547\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.6569 - acc: 0.4679 - val_loss: 1.6702 - val_acc: 0.4560\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.6311 - acc: 0.4773 - val_loss: 1.6456 - val_acc: 0.4689\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.6056 - acc: 0.4879 - val_loss: 1.6409 - val_acc: 0.4664\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.5817 - acc: 0.4925 - val_loss: 1.6149 - val_acc: 0.4720\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.5600 - acc: 0.5005 - val_loss: 1.6017 - val_acc: 0.4769\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.5392 - acc: 0.5102 - val_loss: 1.5884 - val_acc: 0.4855\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.5195 - acc: 0.5156 - val_loss: 1.5657 - val_acc: 0.4894\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.5004 - acc: 0.5242 - val_loss: 1.5654 - val_acc: 0.4880\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.4830 - acc: 0.5269 - val_loss: 1.5527 - val_acc: 0.4884\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.4642 - acc: 0.5337 - val_loss: 1.5714 - val_acc: 0.4902\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.4504 - acc: 0.5400 - val_loss: 1.5390 - val_acc: 0.5017\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.4312 - acc: 0.5459 - val_loss: 1.5233 - val_acc: 0.5025\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.4167 - acc: 0.5510 - val_loss: 1.5246 - val_acc: 0.5006\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.3992 - acc: 0.5565 - val_loss: 1.5162 - val_acc: 0.5117\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.3863 - acc: 0.5621 - val_loss: 1.5611 - val_acc: 0.4971\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.3692 - acc: 0.5672 - val_loss: 1.5007 - val_acc: 0.5130\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.3573 - acc: 0.5724 - val_loss: 1.5041 - val_acc: 0.5130\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 1.3407 - acc: 0.5774 - val_loss: 1.5410 - val_acc: 0.5036\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.3296 - acc: 0.5824 - val_loss: 1.4899 - val_acc: 0.5167\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.3162 - acc: 0.5856 - val_loss: 1.5075 - val_acc: 0.5071\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.3037 - acc: 0.5908 - val_loss: 1.4740 - val_acc: 0.5275\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.2879 - acc: 0.5964 - val_loss: 1.4924 - val_acc: 0.5152\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.2762 - acc: 0.5999 - val_loss: 1.4967 - val_acc: 0.5226\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.2627 - acc: 0.6044 - val_loss: 1.4662 - val_acc: 0.5291\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 1.2530 - acc: 0.6082 - val_loss: 1.5025 - val_acc: 0.5159\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.2382 - acc: 0.6140 - val_loss: 1.5160 - val_acc: 0.5188\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.2252 - acc: 0.6203 - val_loss: 1.5180 - val_acc: 0.5114\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.2152 - acc: 0.6226 - val_loss: 1.4688 - val_acc: 0.5331\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.1991 - acc: 0.6278 - val_loss: 1.5501 - val_acc: 0.5094\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.1862 - acc: 0.6337 - val_loss: 1.4613 - val_acc: 0.5344\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.1748 - acc: 0.6360 - val_loss: 1.4781 - val_acc: 0.5315\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.1668 - acc: 0.6392 - val_loss: 1.5025 - val_acc: 0.5254\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.1529 - acc: 0.6439 - val_loss: 1.5898 - val_acc: 0.5051\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.1435 - acc: 0.6491 - val_loss: 1.5111 - val_acc: 0.5196\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.1314 - acc: 0.6499 - val_loss: 1.5244 - val_acc: 0.5163\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.1157 - acc: 0.6581 - val_loss: 1.5074 - val_acc: 0.5252\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.1087 - acc: 0.6627 - val_loss: 1.6063 - val_acc: 0.4949\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.0979 - acc: 0.6643 - val_loss: 1.5181 - val_acc: 0.5197\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.0823 - acc: 0.6695 - val_loss: 1.5113 - val_acc: 0.5282\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.0724 - acc: 0.6740 - val_loss: 1.4811 - val_acc: 0.5367\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.0590 - acc: 0.6757 - val_loss: 1.5630 - val_acc: 0.5165\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.0479 - acc: 0.6815 - val_loss: 1.5088 - val_acc: 0.5397\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.0322 - acc: 0.6874 - val_loss: 1.5254 - val_acc: 0.5307\n",
      "Experiment with L1 = 0.000000, L2 = 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 2.0716 - acc: 0.2538 - val_loss: 1.8953 - val_acc: 0.3379\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.8296 - acc: 0.3569 - val_loss: 1.7826 - val_acc: 0.3748\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.7448 - acc: 0.3908 - val_loss: 1.7186 - val_acc: 0.3971\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.6828 - acc: 0.4129 - val_loss: 1.6604 - val_acc: 0.4183\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.6332 - acc: 0.4285 - val_loss: 1.6355 - val_acc: 0.4254\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.5912 - acc: 0.4427 - val_loss: 1.5817 - val_acc: 0.4425\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 1.5567 - acc: 0.4534 - val_loss: 1.5539 - val_acc: 0.4515\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.5271 - acc: 0.4638 - val_loss: 1.5600 - val_acc: 0.4475\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.4997 - acc: 0.4735 - val_loss: 1.5145 - val_acc: 0.4638\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.4750 - acc: 0.4823 - val_loss: 1.4930 - val_acc: 0.4723\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.4515 - acc: 0.4901 - val_loss: 1.4843 - val_acc: 0.4737\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.4275 - acc: 0.4984 - val_loss: 1.4699 - val_acc: 0.4770\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.4058 - acc: 0.5043 - val_loss: 1.4512 - val_acc: 0.4854\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.3856 - acc: 0.5136 - val_loss: 1.4288 - val_acc: 0.4955\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.3650 - acc: 0.5170 - val_loss: 1.4581 - val_acc: 0.4843\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.3480 - acc: 0.5235 - val_loss: 1.4147 - val_acc: 0.4985\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.3304 - acc: 0.5323 - val_loss: 1.4214 - val_acc: 0.4931\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.3105 - acc: 0.5381 - val_loss: 1.4013 - val_acc: 0.5032\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.2945 - acc: 0.5436 - val_loss: 1.4397 - val_acc: 0.4838\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.2789 - acc: 0.5496 - val_loss: 1.3877 - val_acc: 0.5126\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.2656 - acc: 0.5539 - val_loss: 1.3938 - val_acc: 0.4988\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2492 - acc: 0.5611 - val_loss: 1.4100 - val_acc: 0.5058\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.2343 - acc: 0.5644 - val_loss: 1.3968 - val_acc: 0.5066\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.2207 - acc: 0.5700 - val_loss: 1.3966 - val_acc: 0.5069\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.2032 - acc: 0.5776 - val_loss: 1.3653 - val_acc: 0.5179\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.1921 - acc: 0.5798 - val_loss: 1.3371 - val_acc: 0.5300\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.1779 - acc: 0.5853 - val_loss: 1.3679 - val_acc: 0.5202\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.1633 - acc: 0.5894 - val_loss: 1.3830 - val_acc: 0.5186\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.1507 - acc: 0.5945 - val_loss: 1.3686 - val_acc: 0.5131\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.1368 - acc: 0.6004 - val_loss: 1.4117 - val_acc: 0.5127\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.1227 - acc: 0.6038 - val_loss: 1.3426 - val_acc: 0.5240\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.1104 - acc: 0.6095 - val_loss: 1.3322 - val_acc: 0.5283\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.0990 - acc: 0.6121 - val_loss: 1.3654 - val_acc: 0.5162\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.0885 - acc: 0.6154 - val_loss: 1.3934 - val_acc: 0.5169\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.0740 - acc: 0.6216 - val_loss: 1.3191 - val_acc: 0.5334\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.0600 - acc: 0.6262 - val_loss: 1.3415 - val_acc: 0.5314\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.0490 - acc: 0.6293 - val_loss: 1.3444 - val_acc: 0.5320\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.0385 - acc: 0.6337 - val_loss: 1.3966 - val_acc: 0.5127\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.0231 - acc: 0.6396 - val_loss: 1.3350 - val_acc: 0.5346\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.0068 - acc: 0.6464 - val_loss: 1.3340 - val_acc: 0.5364\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 0.9990 - acc: 0.6476 - val_loss: 1.3663 - val_acc: 0.5282\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.9860 - acc: 0.6547 - val_loss: 1.3802 - val_acc: 0.5199\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.9750 - acc: 0.6576 - val_loss: 1.3412 - val_acc: 0.5322\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.9657 - acc: 0.6606 - val_loss: 1.4341 - val_acc: 0.5176\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 0.9482 - acc: 0.6654 - val_loss: 1.4148 - val_acc: 0.5219\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 0.9370 - acc: 0.6706 - val_loss: 1.3590 - val_acc: 0.5330\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 0.9264 - acc: 0.6739 - val_loss: 1.5141 - val_acc: 0.5024\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.9153 - acc: 0.6787 - val_loss: 1.3393 - val_acc: 0.5380\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.8994 - acc: 0.6835 - val_loss: 1.4299 - val_acc: 0.5198\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 0.8890 - acc: 0.6898 - val_loss: 1.4853 - val_acc: 0.5122\n",
      "Experiment with L1 = 0.000000, L2 = 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 2.0343 - acc: 0.2738 - val_loss: 1.8766 - val_acc: 0.3456\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.8158 - acc: 0.3633 - val_loss: 1.7739 - val_acc: 0.3811\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.7326 - acc: 0.3945 - val_loss: 1.7000 - val_acc: 0.4043\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.6717 - acc: 0.4173 - val_loss: 1.6571 - val_acc: 0.4224\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.6233 - acc: 0.4333 - val_loss: 1.6184 - val_acc: 0.4275\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.5832 - acc: 0.4455 - val_loss: 1.5796 - val_acc: 0.4451\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.5467 - acc: 0.4590 - val_loss: 1.5597 - val_acc: 0.4498\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.5181 - acc: 0.4678 - val_loss: 1.5346 - val_acc: 0.4580\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.4898 - acc: 0.4769 - val_loss: 1.5000 - val_acc: 0.4731\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.4642 - acc: 0.4873 - val_loss: 1.4843 - val_acc: 0.4774\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.4399 - acc: 0.4959 - val_loss: 1.4784 - val_acc: 0.4748\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.4170 - acc: 0.5029 - val_loss: 1.4731 - val_acc: 0.4799\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.3971 - acc: 0.5108 - val_loss: 1.4417 - val_acc: 0.4857\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.3768 - acc: 0.5175 - val_loss: 1.4491 - val_acc: 0.4790\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.3577 - acc: 0.5232 - val_loss: 1.4458 - val_acc: 0.4837\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.3397 - acc: 0.5297 - val_loss: 1.4641 - val_acc: 0.4843\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.3245 - acc: 0.5330 - val_loss: 1.4123 - val_acc: 0.4994\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.3058 - acc: 0.5405 - val_loss: 1.3934 - val_acc: 0.4977\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.2883 - acc: 0.5467 - val_loss: 1.3953 - val_acc: 0.5017\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.2736 - acc: 0.5499 - val_loss: 1.3969 - val_acc: 0.4991\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.2574 - acc: 0.5569 - val_loss: 1.3873 - val_acc: 0.5071\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.2448 - acc: 0.5618 - val_loss: 1.3640 - val_acc: 0.5127\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.2261 - acc: 0.5705 - val_loss: 1.3864 - val_acc: 0.5078\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.2153 - acc: 0.5713 - val_loss: 1.3510 - val_acc: 0.5239\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.1998 - acc: 0.5768 - val_loss: 1.3491 - val_acc: 0.5243\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.1880 - acc: 0.5811 - val_loss: 1.3635 - val_acc: 0.5144\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.1725 - acc: 0.5848 - val_loss: 1.3674 - val_acc: 0.5112\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.1593 - acc: 0.5904 - val_loss: 1.3516 - val_acc: 0.5186\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.1458 - acc: 0.5966 - val_loss: 1.3495 - val_acc: 0.5242\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.1333 - acc: 0.6020 - val_loss: 1.3638 - val_acc: 0.5212\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.1196 - acc: 0.6048 - val_loss: 1.3662 - val_acc: 0.5196\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.1079 - acc: 0.6098 - val_loss: 1.3520 - val_acc: 0.5215\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.0927 - acc: 0.6166 - val_loss: 1.3829 - val_acc: 0.5144\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.0817 - acc: 0.6192 - val_loss: 1.3337 - val_acc: 0.5337\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.0697 - acc: 0.6218 - val_loss: 1.3674 - val_acc: 0.5216\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.0559 - acc: 0.6294 - val_loss: 1.3692 - val_acc: 0.5216\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.0467 - acc: 0.6306 - val_loss: 1.3461 - val_acc: 0.5321\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.0325 - acc: 0.6386 - val_loss: 1.3398 - val_acc: 0.5289\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.0203 - acc: 0.6408 - val_loss: 1.4263 - val_acc: 0.5152\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.0066 - acc: 0.6473 - val_loss: 1.3810 - val_acc: 0.5228\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 0.9956 - acc: 0.6505 - val_loss: 1.3670 - val_acc: 0.5247\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 0.9827 - acc: 0.6550 - val_loss: 1.3377 - val_acc: 0.5366\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 0.9710 - acc: 0.6565 - val_loss: 1.3542 - val_acc: 0.5343\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.9577 - acc: 0.6648 - val_loss: 1.4162 - val_acc: 0.5198\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.9500 - acc: 0.6657 - val_loss: 1.4230 - val_acc: 0.5222\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.9368 - acc: 0.6718 - val_loss: 1.4047 - val_acc: 0.5219\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.9230 - acc: 0.6744 - val_loss: 1.3767 - val_acc: 0.5290\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 0.9135 - acc: 0.6783 - val_loss: 1.3901 - val_acc: 0.5297\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 0.8986 - acc: 0.6842 - val_loss: 1.4528 - val_acc: 0.5164\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.8839 - acc: 0.6879 - val_loss: 1.3808 - val_acc: 0.5312\n",
      "Experiment with L1 = 0.000000, L2 = 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 2.0362 - acc: 0.2737 - val_loss: 1.8679 - val_acc: 0.3411\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.8101 - acc: 0.3643 - val_loss: 1.7609 - val_acc: 0.3829\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 1.7247 - acc: 0.3931 - val_loss: 1.6982 - val_acc: 0.3944\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 1.6649 - acc: 0.4164 - val_loss: 1.6437 - val_acc: 0.4264\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 1.6180 - acc: 0.4317 - val_loss: 1.6041 - val_acc: 0.4388\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 1.5771 - acc: 0.4481 - val_loss: 1.5666 - val_acc: 0.4475\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 1.5420 - acc: 0.4609 - val_loss: 1.5471 - val_acc: 0.4556\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.5101 - acc: 0.4729 - val_loss: 1.5242 - val_acc: 0.4610\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.4814 - acc: 0.4826 - val_loss: 1.5032 - val_acc: 0.4666\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 1.4532 - acc: 0.4925 - val_loss: 1.4835 - val_acc: 0.4735\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 1.4304 - acc: 0.4983 - val_loss: 1.4610 - val_acc: 0.4832\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 1.4061 - acc: 0.5062 - val_loss: 1.4585 - val_acc: 0.4849\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 1.3855 - acc: 0.5152 - val_loss: 1.4319 - val_acc: 0.4893\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.3634 - acc: 0.5213 - val_loss: 1.4396 - val_acc: 0.4875\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 1.3430 - acc: 0.5288 - val_loss: 1.4163 - val_acc: 0.5008\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 1.3246 - acc: 0.5343 - val_loss: 1.4112 - val_acc: 0.4990\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.3054 - acc: 0.5417 - val_loss: 1.4062 - val_acc: 0.4998\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 1.2885 - acc: 0.5469 - val_loss: 1.3873 - val_acc: 0.5043\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.2730 - acc: 0.5531 - val_loss: 1.3986 - val_acc: 0.5028\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 1.2557 - acc: 0.5582 - val_loss: 1.3762 - val_acc: 0.5115\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 1.2395 - acc: 0.5644 - val_loss: 1.3611 - val_acc: 0.5202\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 1.2218 - acc: 0.5725 - val_loss: 1.3999 - val_acc: 0.5074\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.2100 - acc: 0.5761 - val_loss: 1.4034 - val_acc: 0.5044\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 1.1940 - acc: 0.5811 - val_loss: 1.3550 - val_acc: 0.5202\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.1817 - acc: 0.5846 - val_loss: 1.3692 - val_acc: 0.5147\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.1658 - acc: 0.5911 - val_loss: 1.3510 - val_acc: 0.5256\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 1.1502 - acc: 0.5968 - val_loss: 1.3650 - val_acc: 0.5180\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.1377 - acc: 0.6006 - val_loss: 1.3746 - val_acc: 0.5174\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.1237 - acc: 0.6074 - val_loss: 1.3767 - val_acc: 0.5194\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 1.1119 - acc: 0.6108 - val_loss: 1.3521 - val_acc: 0.5227\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 1.0973 - acc: 0.6167 - val_loss: 1.3808 - val_acc: 0.5238\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.0843 - acc: 0.6203 - val_loss: 1.3210 - val_acc: 0.5308\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 1.0719 - acc: 0.6234 - val_loss: 1.3410 - val_acc: 0.5262\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 1.0612 - acc: 0.6251 - val_loss: 1.3716 - val_acc: 0.5207\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 1.0427 - acc: 0.6354 - val_loss: 1.3664 - val_acc: 0.5256\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.0290 - acc: 0.6383 - val_loss: 1.3743 - val_acc: 0.5276\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.0198 - acc: 0.6437 - val_loss: 1.4175 - val_acc: 0.5154\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 1.0087 - acc: 0.6446 - val_loss: 1.3465 - val_acc: 0.5332\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.9958 - acc: 0.6506 - val_loss: 1.3448 - val_acc: 0.5344\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.9837 - acc: 0.6547 - val_loss: 1.3643 - val_acc: 0.5366\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 0.9696 - acc: 0.6616 - val_loss: 1.3448 - val_acc: 0.5428\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 0.9576 - acc: 0.6641 - val_loss: 1.3759 - val_acc: 0.5274\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.9459 - acc: 0.6692 - val_loss: 1.3537 - val_acc: 0.5330\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 0.9303 - acc: 0.6744 - val_loss: 1.5593 - val_acc: 0.4964\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.9220 - acc: 0.6751 - val_loss: 1.4386 - val_acc: 0.5197\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.9098 - acc: 0.6812 - val_loss: 1.3932 - val_acc: 0.5325\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.8957 - acc: 0.6848 - val_loss: 1.3828 - val_acc: 0.5370\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 0.8824 - acc: 0.6908 - val_loss: 1.4209 - val_acc: 0.5304\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.8760 - acc: 0.6919 - val_loss: 1.4015 - val_acc: 0.5282\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.8584 - acc: 0.6991 - val_loss: 1.6914 - val_acc: 0.4762\n",
      "Experiment with L1 = 0.000000, L2 = 0.010000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 15.0921 - acc: 0.2607 - val_loss: 13.9635 - val_acc: 0.3338\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 13.0241 - acc: 0.3524 - val_loss: 12.1352 - val_acc: 0.3632\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 11.3489 - acc: 0.3765 - val_loss: 10.5975 - val_acc: 0.3904\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 9.9372 - acc: 0.3935 - val_loss: 9.2987 - val_acc: 0.3976\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 8.7368 - acc: 0.4033 - val_loss: 8.1952 - val_acc: 0.4072\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 7.7148 - acc: 0.4105 - val_loss: 7.2506 - val_acc: 0.4161\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 6.8429 - acc: 0.4181 - val_loss: 6.4506 - val_acc: 0.4227\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 6.0988 - acc: 0.4250 - val_loss: 5.7664 - val_acc: 0.4242\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 5.4624 - acc: 0.4308 - val_loss: 5.1866 - val_acc: 0.4247\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 4.9197 - acc: 0.4355 - val_loss: 4.6889 - val_acc: 0.4207\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 4.4564 - acc: 0.4395 - val_loss: 4.2641 - val_acc: 0.4303\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 4.0578 - acc: 0.4454 - val_loss: 3.8912 - val_acc: 0.4371\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 3.7170 - acc: 0.4487 - val_loss: 3.5704 - val_acc: 0.4433\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 5s 99us/step - loss: 3.4246 - acc: 0.4505 - val_loss: 3.3005 - val_acc: 0.4503\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 3.1753 - acc: 0.4554 - val_loss: 3.0779 - val_acc: 0.4505\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 2.9606 - acc: 0.4580 - val_loss: 2.8693 - val_acc: 0.4578\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 2.7754 - acc: 0.4619 - val_loss: 2.7057 - val_acc: 0.4579\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 2.6190 - acc: 0.4637 - val_loss: 2.5818 - val_acc: 0.4493\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 2.4833 - acc: 0.4683 - val_loss: 2.4467 - val_acc: 0.4551\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 2.3671 - acc: 0.4696 - val_loss: 2.3505 - val_acc: 0.4613\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 2.2679 - acc: 0.4711 - val_loss: 2.2645 - val_acc: 0.4556\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 2.1817 - acc: 0.4754 - val_loss: 2.1593 - val_acc: 0.4720\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 2.1074 - acc: 0.4771 - val_loss: 2.1062 - val_acc: 0.4682\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 2.0441 - acc: 0.4790 - val_loss: 2.0520 - val_acc: 0.4661\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.9890 - acc: 0.4821 - val_loss: 1.9863 - val_acc: 0.4741\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.9422 - acc: 0.4835 - val_loss: 1.9584 - val_acc: 0.4680\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.9010 - acc: 0.4847 - val_loss: 1.9946 - val_acc: 0.4410\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.8653 - acc: 0.4877 - val_loss: 1.8990 - val_acc: 0.4690\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.8337 - acc: 0.4885 - val_loss: 1.8401 - val_acc: 0.4801\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.8064 - acc: 0.4913 - val_loss: 1.8210 - val_acc: 0.4822\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.7821 - acc: 0.4932 - val_loss: 1.8158 - val_acc: 0.4722\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.7621 - acc: 0.4936 - val_loss: 1.7786 - val_acc: 0.4921\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.7431 - acc: 0.4981 - val_loss: 1.7608 - val_acc: 0.4898\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.7272 - acc: 0.4992 - val_loss: 1.8077 - val_acc: 0.4703\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.7130 - acc: 0.4997 - val_loss: 1.7675 - val_acc: 0.4754\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.7007 - acc: 0.5025 - val_loss: 1.7399 - val_acc: 0.4795\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.6914 - acc: 0.5027 - val_loss: 1.7997 - val_acc: 0.4549\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.6808 - acc: 0.5066 - val_loss: 1.7290 - val_acc: 0.4889\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 1.6718 - acc: 0.5065 - val_loss: 1.7152 - val_acc: 0.4913\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.6655 - acc: 0.5078 - val_loss: 1.7235 - val_acc: 0.4827\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.6584 - acc: 0.5080 - val_loss: 1.7013 - val_acc: 0.4878\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.6496 - acc: 0.5125 - val_loss: 1.6957 - val_acc: 0.4945\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.6428 - acc: 0.5116 - val_loss: 1.7845 - val_acc: 0.4527\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.6386 - acc: 0.5170 - val_loss: 1.6916 - val_acc: 0.4942\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.6344 - acc: 0.5158 - val_loss: 1.6787 - val_acc: 0.4975\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.6279 - acc: 0.5171 - val_loss: 1.6794 - val_acc: 0.4975\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.6235 - acc: 0.5193 - val_loss: 1.6695 - val_acc: 0.5006\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.6198 - acc: 0.5207 - val_loss: 1.7014 - val_acc: 0.4788\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.6174 - acc: 0.5226 - val_loss: 1.6881 - val_acc: 0.4968\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.6148 - acc: 0.5212 - val_loss: 1.7034 - val_acc: 0.4846\n",
      "Experiment with L1 = 0.000000, L2 = 0.000100\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 2.1463 - acc: 0.2869 - val_loss: 1.9881 - val_acc: 0.3532\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.9292 - acc: 0.3718 - val_loss: 1.8847 - val_acc: 0.3877\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.8477 - acc: 0.4014 - val_loss: 1.8177 - val_acc: 0.4138\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.7889 - acc: 0.4203 - val_loss: 1.7750 - val_acc: 0.4244\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 1.7417 - acc: 0.4383 - val_loss: 1.7429 - val_acc: 0.4340\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.7042 - acc: 0.4510 - val_loss: 1.7083 - val_acc: 0.4414\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.6718 - acc: 0.4618 - val_loss: 1.6732 - val_acc: 0.4604\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.6421 - acc: 0.4735 - val_loss: 1.6637 - val_acc: 0.4611\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.6176 - acc: 0.4816 - val_loss: 1.6433 - val_acc: 0.4634\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.5950 - acc: 0.4892 - val_loss: 1.6191 - val_acc: 0.4757\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.5723 - acc: 0.4971 - val_loss: 1.6122 - val_acc: 0.4781\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 1.5504 - acc: 0.5034 - val_loss: 1.6027 - val_acc: 0.4759\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.5299 - acc: 0.5115 - val_loss: 1.5781 - val_acc: 0.4950\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.5081 - acc: 0.5190 - val_loss: 1.6043 - val_acc: 0.4818\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.4922 - acc: 0.5232 - val_loss: 1.5688 - val_acc: 0.4923\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.4726 - acc: 0.5295 - val_loss: 1.5553 - val_acc: 0.4976\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.4552 - acc: 0.5364 - val_loss: 1.5381 - val_acc: 0.5032\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.4395 - acc: 0.5430 - val_loss: 1.5376 - val_acc: 0.5007\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.4205 - acc: 0.5476 - val_loss: 1.5312 - val_acc: 0.5042\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 1.4059 - acc: 0.5534 - val_loss: 1.5357 - val_acc: 0.5054\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.3901 - acc: 0.5593 - val_loss: 1.5068 - val_acc: 0.5130\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.3753 - acc: 0.5649 - val_loss: 1.5137 - val_acc: 0.5066\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.3589 - acc: 0.5714 - val_loss: 1.5121 - val_acc: 0.5088\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.3466 - acc: 0.5758 - val_loss: 1.5703 - val_acc: 0.5026\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.3344 - acc: 0.5786 - val_loss: 1.5298 - val_acc: 0.5124\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.3181 - acc: 0.5860 - val_loss: 1.4798 - val_acc: 0.5229\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.3024 - acc: 0.5918 - val_loss: 1.5393 - val_acc: 0.5115\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.2917 - acc: 0.5926 - val_loss: 1.5064 - val_acc: 0.5133\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.2774 - acc: 0.5985 - val_loss: 1.4812 - val_acc: 0.5288\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.2632 - acc: 0.6040 - val_loss: 1.6095 - val_acc: 0.4879\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.2528 - acc: 0.6061 - val_loss: 1.5656 - val_acc: 0.5033\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.2378 - acc: 0.6139 - val_loss: 1.4917 - val_acc: 0.5258\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.2254 - acc: 0.6176 - val_loss: 1.4754 - val_acc: 0.5256\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 1.2124 - acc: 0.6222 - val_loss: 1.5147 - val_acc: 0.5220\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.1974 - acc: 0.6267 - val_loss: 1.4918 - val_acc: 0.5263\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.1879 - acc: 0.6281 - val_loss: 1.4621 - val_acc: 0.5339\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.1751 - acc: 0.6359 - val_loss: 1.4605 - val_acc: 0.5360\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.1594 - acc: 0.6413 - val_loss: 1.5055 - val_acc: 0.5194\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.1472 - acc: 0.6444 - val_loss: 1.5206 - val_acc: 0.5267\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.1376 - acc: 0.6498 - val_loss: 1.4646 - val_acc: 0.5356\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.1239 - acc: 0.6544 - val_loss: 1.4893 - val_acc: 0.5327\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.1114 - acc: 0.6582 - val_loss: 1.5227 - val_acc: 0.5237\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.1003 - acc: 0.6634 - val_loss: 1.5417 - val_acc: 0.5221\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.0902 - acc: 0.6671 - val_loss: 1.5047 - val_acc: 0.5333\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 1.0833 - acc: 0.6682 - val_loss: 1.5517 - val_acc: 0.5206\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.0647 - acc: 0.6760 - val_loss: 1.4737 - val_acc: 0.5348\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.0529 - acc: 0.6802 - val_loss: 1.5226 - val_acc: 0.5294\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.0430 - acc: 0.6822 - val_loss: 1.5379 - val_acc: 0.5236\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.0337 - acc: 0.6876 - val_loss: 1.6558 - val_acc: 0.5012\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 1.0229 - acc: 0.6905 - val_loss: 1.6102 - val_acc: 0.5135\n",
      "Experiment with L1 = 0.000000, L2 = 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 2.0428 - acc: 0.2676 - val_loss: 1.8791 - val_acc: 0.3365\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.8142 - acc: 0.3627 - val_loss: 1.7653 - val_acc: 0.3793\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.7279 - acc: 0.3983 - val_loss: 1.7015 - val_acc: 0.4054\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 1.6686 - acc: 0.4161 - val_loss: 1.6508 - val_acc: 0.4185\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.6202 - acc: 0.4327 - val_loss: 1.6096 - val_acc: 0.4355\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.5810 - acc: 0.4477 - val_loss: 1.5767 - val_acc: 0.4465\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.5453 - acc: 0.4591 - val_loss: 1.5713 - val_acc: 0.4454\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.5172 - acc: 0.4693 - val_loss: 1.5233 - val_acc: 0.4664\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 1.4897 - acc: 0.4767 - val_loss: 1.5063 - val_acc: 0.4683\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.4635 - acc: 0.4871 - val_loss: 1.4907 - val_acc: 0.4725\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.4407 - acc: 0.4926 - val_loss: 1.4665 - val_acc: 0.4813\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.4180 - acc: 0.4995 - val_loss: 1.4740 - val_acc: 0.4766\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.3972 - acc: 0.5072 - val_loss: 1.4474 - val_acc: 0.4821\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.3763 - acc: 0.5145 - val_loss: 1.4297 - val_acc: 0.4909\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.3569 - acc: 0.5231 - val_loss: 1.4356 - val_acc: 0.4908\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.3382 - acc: 0.5285 - val_loss: 1.4037 - val_acc: 0.5004\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.3199 - acc: 0.5363 - val_loss: 1.4340 - val_acc: 0.4966\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.3014 - acc: 0.5423 - val_loss: 1.3840 - val_acc: 0.5056\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 1.2851 - acc: 0.5486 - val_loss: 1.3939 - val_acc: 0.5035\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.2707 - acc: 0.5541 - val_loss: 1.4118 - val_acc: 0.5005\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2554 - acc: 0.5576 - val_loss: 1.3940 - val_acc: 0.5045\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.2381 - acc: 0.5645 - val_loss: 1.3932 - val_acc: 0.5107\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.2254 - acc: 0.5683 - val_loss: 1.3767 - val_acc: 0.5080\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2088 - acc: 0.5744 - val_loss: 1.3515 - val_acc: 0.5213\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.1974 - acc: 0.5804 - val_loss: 1.3598 - val_acc: 0.5156\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.1825 - acc: 0.5847 - val_loss: 1.3592 - val_acc: 0.5206\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.1686 - acc: 0.5898 - val_loss: 1.3905 - val_acc: 0.5080\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.1538 - acc: 0.5939 - val_loss: 1.4227 - val_acc: 0.5006\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.1399 - acc: 0.5993 - val_loss: 1.3897 - val_acc: 0.5101\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.1280 - acc: 0.6050 - val_loss: 1.3338 - val_acc: 0.5300\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.1151 - acc: 0.6076 - val_loss: 1.3684 - val_acc: 0.5201\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 1.1013 - acc: 0.6134 - val_loss: 1.3835 - val_acc: 0.5208\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.0892 - acc: 0.6157 - val_loss: 1.3900 - val_acc: 0.5146\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.0769 - acc: 0.6231 - val_loss: 1.3608 - val_acc: 0.5257\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.0597 - acc: 0.6266 - val_loss: 1.3992 - val_acc: 0.5148\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.0551 - acc: 0.6323 - val_loss: 1.3748 - val_acc: 0.5163\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.0370 - acc: 0.6358 - val_loss: 1.3622 - val_acc: 0.5247\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.0214 - acc: 0.6417 - val_loss: 1.3471 - val_acc: 0.5321\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.0125 - acc: 0.6444 - val_loss: 1.3588 - val_acc: 0.5332\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 0.9998 - acc: 0.6508 - val_loss: 1.3473 - val_acc: 0.5338\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.9866 - acc: 0.6542 - val_loss: 1.4697 - val_acc: 0.5052\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 0.9756 - acc: 0.6558 - val_loss: 1.4033 - val_acc: 0.5187\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.9635 - acc: 0.6625 - val_loss: 1.3775 - val_acc: 0.5255\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 0.9540 - acc: 0.6656 - val_loss: 1.3504 - val_acc: 0.5324\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.9389 - acc: 0.6719 - val_loss: 1.3992 - val_acc: 0.5194\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.9256 - acc: 0.6775 - val_loss: 1.3637 - val_acc: 0.5335\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.9158 - acc: 0.6795 - val_loss: 1.4127 - val_acc: 0.5212\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 0.9051 - acc: 0.6811 - val_loss: 1.3642 - val_acc: 0.5352\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 0.8909 - acc: 0.6895 - val_loss: 1.5136 - val_acc: 0.5091\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 0.8824 - acc: 0.6913 - val_loss: 1.3891 - val_acc: 0.5300\n",
      "Experiment with L1 = 0.000000, L2 = 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 2.0251 - acc: 0.2736 - val_loss: 1.8731 - val_acc: 0.3326\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.8078 - acc: 0.3646 - val_loss: 1.7652 - val_acc: 0.3842\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.7225 - acc: 0.3948 - val_loss: 1.6972 - val_acc: 0.4050\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.6613 - acc: 0.4159 - val_loss: 1.6433 - val_acc: 0.4254\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.6144 - acc: 0.4336 - val_loss: 1.6085 - val_acc: 0.4332\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.5742 - acc: 0.4465 - val_loss: 1.5756 - val_acc: 0.4444\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.5414 - acc: 0.4602 - val_loss: 1.5520 - val_acc: 0.4533\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.5133 - acc: 0.4690 - val_loss: 1.5219 - val_acc: 0.4632\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.4861 - acc: 0.4791 - val_loss: 1.5049 - val_acc: 0.4651\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.4624 - acc: 0.4858 - val_loss: 1.4857 - val_acc: 0.4718\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.4384 - acc: 0.4936 - val_loss: 1.4779 - val_acc: 0.4783\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.4162 - acc: 0.5013 - val_loss: 1.4555 - val_acc: 0.4837\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.3935 - acc: 0.5090 - val_loss: 1.4449 - val_acc: 0.4885\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.3733 - acc: 0.5159 - val_loss: 1.4674 - val_acc: 0.4777\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.3559 - acc: 0.5223 - val_loss: 1.4378 - val_acc: 0.4859\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.3379 - acc: 0.5277 - val_loss: 1.4222 - val_acc: 0.4971\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.3201 - acc: 0.5346 - val_loss: 1.4344 - val_acc: 0.4911\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.3029 - acc: 0.5409 - val_loss: 1.4022 - val_acc: 0.4990\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.2860 - acc: 0.5473 - val_loss: 1.4242 - val_acc: 0.4910\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.2702 - acc: 0.5521 - val_loss: 1.3918 - val_acc: 0.5025\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.2562 - acc: 0.5572 - val_loss: 1.3833 - val_acc: 0.5047\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2383 - acc: 0.5617 - val_loss: 1.3800 - val_acc: 0.5120\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.2257 - acc: 0.5669 - val_loss: 1.4715 - val_acc: 0.4865\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.2123 - acc: 0.5725 - val_loss: 1.3624 - val_acc: 0.5194\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.1947 - acc: 0.5809 - val_loss: 1.3849 - val_acc: 0.5134\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.1830 - acc: 0.5833 - val_loss: 1.3757 - val_acc: 0.5153\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.1678 - acc: 0.5902 - val_loss: 1.3456 - val_acc: 0.5254\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.1553 - acc: 0.5925 - val_loss: 1.3560 - val_acc: 0.5178\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.1423 - acc: 0.5994 - val_loss: 1.3431 - val_acc: 0.5257\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.1287 - acc: 0.6025 - val_loss: 1.3562 - val_acc: 0.5212\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.1164 - acc: 0.6085 - val_loss: 1.3849 - val_acc: 0.5178\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.1027 - acc: 0.6105 - val_loss: 1.3524 - val_acc: 0.5283\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 1.0912 - acc: 0.6154 - val_loss: 1.3406 - val_acc: 0.5292\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 1.0752 - acc: 0.6207 - val_loss: 1.3237 - val_acc: 0.5284\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.0638 - acc: 0.6243 - val_loss: 1.3489 - val_acc: 0.5243\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.0516 - acc: 0.6286 - val_loss: 1.3606 - val_acc: 0.5305\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.0407 - acc: 0.6350 - val_loss: 1.3807 - val_acc: 0.5240\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 1.0274 - acc: 0.6379 - val_loss: 1.3579 - val_acc: 0.5286\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.0162 - acc: 0.6452 - val_loss: 1.3398 - val_acc: 0.5319\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.0030 - acc: 0.6482 - val_loss: 1.3933 - val_acc: 0.5235\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.9940 - acc: 0.6498 - val_loss: 1.3688 - val_acc: 0.5248\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.9769 - acc: 0.6556 - val_loss: 1.3731 - val_acc: 0.5245\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 0.9673 - acc: 0.6611 - val_loss: 1.3597 - val_acc: 0.5290\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.9541 - acc: 0.6658 - val_loss: 1.3912 - val_acc: 0.5227\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.9427 - acc: 0.6686 - val_loss: 1.3621 - val_acc: 0.5320\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 0.9313 - acc: 0.6736 - val_loss: 1.3662 - val_acc: 0.5297\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.9156 - acc: 0.6806 - val_loss: 1.4015 - val_acc: 0.5219\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.9078 - acc: 0.6809 - val_loss: 1.4185 - val_acc: 0.5182\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.8974 - acc: 0.6840 - val_loss: 1.3872 - val_acc: 0.5303\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.8857 - acc: 0.6889 - val_loss: 1.3653 - val_acc: 0.5333\n",
      "Experiment with L1 = 0.000000, L2 = 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 2.0341 - acc: 0.2732 - val_loss: 1.8735 - val_acc: 0.3399\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.8114 - acc: 0.3638 - val_loss: 1.7582 - val_acc: 0.3876\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.7258 - acc: 0.3967 - val_loss: 1.7074 - val_acc: 0.4008\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.6685 - acc: 0.4151 - val_loss: 1.6490 - val_acc: 0.4268\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.6215 - acc: 0.4333 - val_loss: 1.6102 - val_acc: 0.4330\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 1.5849 - acc: 0.4478 - val_loss: 1.5787 - val_acc: 0.4469\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.5522 - acc: 0.4555 - val_loss: 1.5530 - val_acc: 0.4543\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.5212 - acc: 0.4693 - val_loss: 1.5413 - val_acc: 0.4564\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.4947 - acc: 0.4759 - val_loss: 1.5258 - val_acc: 0.4580\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.4700 - acc: 0.4848 - val_loss: 1.5052 - val_acc: 0.4665\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.4451 - acc: 0.4954 - val_loss: 1.4912 - val_acc: 0.4746\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.4235 - acc: 0.5004 - val_loss: 1.4694 - val_acc: 0.4829\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.4015 - acc: 0.5065 - val_loss: 1.4479 - val_acc: 0.4847\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.3799 - acc: 0.5164 - val_loss: 1.4489 - val_acc: 0.4851\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.3629 - acc: 0.5218 - val_loss: 1.4331 - val_acc: 0.4887\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.3414 - acc: 0.5281 - val_loss: 1.4218 - val_acc: 0.4935\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.3230 - acc: 0.5355 - val_loss: 1.4183 - val_acc: 0.4951\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.3048 - acc: 0.5412 - val_loss: 1.4187 - val_acc: 0.4946\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.2899 - acc: 0.5469 - val_loss: 1.3828 - val_acc: 0.5089\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.2735 - acc: 0.5522 - val_loss: 1.3855 - val_acc: 0.5081\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.2586 - acc: 0.5567 - val_loss: 1.3922 - val_acc: 0.5060\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.2431 - acc: 0.5632 - val_loss: 1.3980 - val_acc: 0.5075\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.2272 - acc: 0.5695 - val_loss: 1.3752 - val_acc: 0.5183\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.2115 - acc: 0.5740 - val_loss: 1.4034 - val_acc: 0.5076\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 4s 74us/step - loss: 1.1980 - acc: 0.5793 - val_loss: 1.3763 - val_acc: 0.5120\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.1829 - acc: 0.5841 - val_loss: 1.3533 - val_acc: 0.5213\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.1704 - acc: 0.5880 - val_loss: 1.3585 - val_acc: 0.5190\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.1592 - acc: 0.5924 - val_loss: 1.3425 - val_acc: 0.5234\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.1388 - acc: 0.5986 - val_loss: 1.4054 - val_acc: 0.5033\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.1318 - acc: 0.6032 - val_loss: 1.3933 - val_acc: 0.5095\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.1177 - acc: 0.6071 - val_loss: 1.3714 - val_acc: 0.5146\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.1008 - acc: 0.6118 - val_loss: 1.3730 - val_acc: 0.5158\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.0930 - acc: 0.6173 - val_loss: 1.3474 - val_acc: 0.5246\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.0763 - acc: 0.6222 - val_loss: 1.3532 - val_acc: 0.5284\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.0644 - acc: 0.6272 - val_loss: 1.3543 - val_acc: 0.5227\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.0508 - acc: 0.6313 - val_loss: 1.3421 - val_acc: 0.5252\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.0372 - acc: 0.6349 - val_loss: 1.3564 - val_acc: 0.5250\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.0285 - acc: 0.6375 - val_loss: 1.3717 - val_acc: 0.5226\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.0118 - acc: 0.6433 - val_loss: 1.3531 - val_acc: 0.5260\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.9989 - acc: 0.6473 - val_loss: 1.3696 - val_acc: 0.5235\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.9899 - acc: 0.6519 - val_loss: 1.3703 - val_acc: 0.5225\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.9765 - acc: 0.6583 - val_loss: 1.3475 - val_acc: 0.5316\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.9648 - acc: 0.6603 - val_loss: 1.4011 - val_acc: 0.5199\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.9489 - acc: 0.6662 - val_loss: 1.3619 - val_acc: 0.5288\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 0.9450 - acc: 0.6664 - val_loss: 1.3987 - val_acc: 0.5202\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 0.9291 - acc: 0.6734 - val_loss: 1.4656 - val_acc: 0.4976\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 0.9169 - acc: 0.6777 - val_loss: 1.4508 - val_acc: 0.5072\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 0.9040 - acc: 0.6834 - val_loss: 1.5698 - val_acc: 0.4881\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.8940 - acc: 0.6849 - val_loss: 1.3755 - val_acc: 0.5313\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.8809 - acc: 0.6928 - val_loss: 1.3993 - val_acc: 0.5317\n",
      "Experiment with L1 = 0.000000, L2 = 0.010000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 15.0853 - acc: 0.2748 - val_loss: 13.9523 - val_acc: 0.3434\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 13.0183 - acc: 0.3613 - val_loss: 12.1252 - val_acc: 0.3787\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 4s 74us/step - loss: 11.3456 - acc: 0.3834 - val_loss: 10.5932 - val_acc: 0.3979\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 4s 74us/step - loss: 9.9337 - acc: 0.3983 - val_loss: 9.2979 - val_acc: 0.3974\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 8.7326 - acc: 0.4087 - val_loss: 8.1973 - val_acc: 0.3993\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 7.7110 - acc: 0.4156 - val_loss: 7.2509 - val_acc: 0.4149\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 6.8379 - acc: 0.4227 - val_loss: 6.4449 - val_acc: 0.4192\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 6.0922 - acc: 0.4280 - val_loss: 5.7633 - val_acc: 0.4226\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 5.4571 - acc: 0.4333 - val_loss: 5.1796 - val_acc: 0.4308\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 4.9123 - acc: 0.4396 - val_loss: 4.6765 - val_acc: 0.4332\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 4.4470 - acc: 0.4426 - val_loss: 4.2443 - val_acc: 0.4415\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 4.0503 - acc: 0.4478 - val_loss: 3.8766 - val_acc: 0.4434\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 3.7084 - acc: 0.4531 - val_loss: 3.5682 - val_acc: 0.4421\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 3.4177 - acc: 0.4548 - val_loss: 3.3013 - val_acc: 0.4455\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 3.1665 - acc: 0.4575 - val_loss: 3.0628 - val_acc: 0.4504\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 2.9523 - acc: 0.4619 - val_loss: 2.8834 - val_acc: 0.4524\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 2.7685 - acc: 0.4669 - val_loss: 2.7073 - val_acc: 0.4502\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 2.6117 - acc: 0.4697 - val_loss: 2.5533 - val_acc: 0.4629\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 2.4775 - acc: 0.4704 - val_loss: 2.4320 - val_acc: 0.4670\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 2.3615 - acc: 0.4734 - val_loss: 2.3592 - val_acc: 0.4547\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 2.2635 - acc: 0.4739 - val_loss: 2.2337 - val_acc: 0.4717\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 2.1754 - acc: 0.4787 - val_loss: 2.1541 - val_acc: 0.4704\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 2.1024 - acc: 0.4811 - val_loss: 2.1061 - val_acc: 0.4696\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 2.0396 - acc: 0.4826 - val_loss: 2.0311 - val_acc: 0.4720\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 4s 74us/step - loss: 1.9843 - acc: 0.4839 - val_loss: 1.9832 - val_acc: 0.4762\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 4s 74us/step - loss: 1.9350 - acc: 0.4891 - val_loss: 1.9381 - val_acc: 0.4750\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.8937 - acc: 0.4894 - val_loss: 1.9022 - val_acc: 0.4763\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.8584 - acc: 0.4938 - val_loss: 1.8708 - val_acc: 0.4844\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.8280 - acc: 0.4951 - val_loss: 1.8538 - val_acc: 0.4853\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.8008 - acc: 0.4946 - val_loss: 1.8519 - val_acc: 0.4617\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.7757 - acc: 0.4981 - val_loss: 1.7984 - val_acc: 0.4918\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.7550 - acc: 0.5014 - val_loss: 1.7838 - val_acc: 0.4845\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7386 - acc: 0.5023 - val_loss: 1.7760 - val_acc: 0.4777\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7231 - acc: 0.5041 - val_loss: 1.7624 - val_acc: 0.4906\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.7079 - acc: 0.5062 - val_loss: 1.7611 - val_acc: 0.4881\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.6983 - acc: 0.5071 - val_loss: 1.7687 - val_acc: 0.4767\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.6860 - acc: 0.5061 - val_loss: 1.7258 - val_acc: 0.4944\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.6766 - acc: 0.5105 - val_loss: 1.7088 - val_acc: 0.4941\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.6674 - acc: 0.5111 - val_loss: 1.7134 - val_acc: 0.4909\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.6593 - acc: 0.5111 - val_loss: 1.8085 - val_acc: 0.4479\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.6530 - acc: 0.5132 - val_loss: 1.7609 - val_acc: 0.4808\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.6453 - acc: 0.5144 - val_loss: 1.6977 - val_acc: 0.4937\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.6393 - acc: 0.5165 - val_loss: 1.7120 - val_acc: 0.4834\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.6352 - acc: 0.5176 - val_loss: 1.7300 - val_acc: 0.4747\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.6292 - acc: 0.5192 - val_loss: 1.7235 - val_acc: 0.4743\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.6254 - acc: 0.5220 - val_loss: 1.6741 - val_acc: 0.4999\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.6233 - acc: 0.5212 - val_loss: 1.6729 - val_acc: 0.5033\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.6184 - acc: 0.5188 - val_loss: 1.6809 - val_acc: 0.4955\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.6142 - acc: 0.5233 - val_loss: 1.7367 - val_acc: 0.4781\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.6111 - acc: 0.5263 - val_loss: 1.7033 - val_acc: 0.4911\n",
      "Experiment with L1 = 0.000000, L2 = 0.000100\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 2.1731 - acc: 0.2729 - val_loss: 1.9978 - val_acc: 0.3507\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.9459 - acc: 0.3649 - val_loss: 1.8919 - val_acc: 0.3839\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.8632 - acc: 0.3936 - val_loss: 1.8450 - val_acc: 0.3965\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.8048 - acc: 0.4167 - val_loss: 1.7898 - val_acc: 0.4214\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.7565 - acc: 0.4348 - val_loss: 1.7428 - val_acc: 0.4304\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7150 - acc: 0.4511 - val_loss: 1.7060 - val_acc: 0.4529\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.6790 - acc: 0.4631 - val_loss: 1.6779 - val_acc: 0.4586\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 1.6486 - acc: 0.4713 - val_loss: 1.6763 - val_acc: 0.4592\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.6225 - acc: 0.4792 - val_loss: 1.6336 - val_acc: 0.4770\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.5950 - acc: 0.4889 - val_loss: 1.6189 - val_acc: 0.4784\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.5706 - acc: 0.4956 - val_loss: 1.6027 - val_acc: 0.4801\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.5492 - acc: 0.5046 - val_loss: 1.5894 - val_acc: 0.4836\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 1.5264 - acc: 0.5133 - val_loss: 1.5822 - val_acc: 0.4856\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 1.5069 - acc: 0.5181 - val_loss: 1.5710 - val_acc: 0.4956\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.4872 - acc: 0.5272 - val_loss: 1.5658 - val_acc: 0.4896\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.4687 - acc: 0.5331 - val_loss: 1.5372 - val_acc: 0.5044\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.4522 - acc: 0.5391 - val_loss: 1.5358 - val_acc: 0.5038\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.4354 - acc: 0.5442 - val_loss: 1.5398 - val_acc: 0.5005\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.4182 - acc: 0.5513 - val_loss: 1.5061 - val_acc: 0.5174\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.4025 - acc: 0.5558 - val_loss: 1.5166 - val_acc: 0.5122\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.3853 - acc: 0.5613 - val_loss: 1.5215 - val_acc: 0.5126\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 1.3699 - acc: 0.5682 - val_loss: 1.5321 - val_acc: 0.5083\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 1.3569 - acc: 0.5712 - val_loss: 1.4987 - val_acc: 0.5164\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.3416 - acc: 0.5764 - val_loss: 1.5071 - val_acc: 0.5145\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 1.3281 - acc: 0.5838 - val_loss: 1.5155 - val_acc: 0.5187\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.3134 - acc: 0.5868 - val_loss: 1.4778 - val_acc: 0.5232\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.2999 - acc: 0.5926 - val_loss: 1.4874 - val_acc: 0.5216\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.2880 - acc: 0.5975 - val_loss: 1.4869 - val_acc: 0.5263\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.2707 - acc: 0.6006 - val_loss: 1.5772 - val_acc: 0.4881\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.2581 - acc: 0.6066 - val_loss: 1.5046 - val_acc: 0.5168\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 1.2455 - acc: 0.6109 - val_loss: 1.5052 - val_acc: 0.5259\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.2323 - acc: 0.6181 - val_loss: 1.5000 - val_acc: 0.5250\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.2199 - acc: 0.6206 - val_loss: 1.4681 - val_acc: 0.5279\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.2067 - acc: 0.6256 - val_loss: 1.4875 - val_acc: 0.5241\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.1947 - acc: 0.6301 - val_loss: 1.5005 - val_acc: 0.5202\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.1819 - acc: 0.6339 - val_loss: 1.5022 - val_acc: 0.5221\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.1695 - acc: 0.6394 - val_loss: 1.4899 - val_acc: 0.5260\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.1537 - acc: 0.6450 - val_loss: 1.4959 - val_acc: 0.5286\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.1462 - acc: 0.6457 - val_loss: 1.5186 - val_acc: 0.5166\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.1352 - acc: 0.6510 - val_loss: 1.5006 - val_acc: 0.5323\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.1199 - acc: 0.6568 - val_loss: 1.4620 - val_acc: 0.5373\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.1085 - acc: 0.6601 - val_loss: 1.4960 - val_acc: 0.5273\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.0999 - acc: 0.6633 - val_loss: 1.5298 - val_acc: 0.5232\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.0869 - acc: 0.6694 - val_loss: 1.4673 - val_acc: 0.5410\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.0701 - acc: 0.6738 - val_loss: 1.5953 - val_acc: 0.5133\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.0657 - acc: 0.6755 - val_loss: 1.4768 - val_acc: 0.5438\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.0540 - acc: 0.6801 - val_loss: 1.5356 - val_acc: 0.5314\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.0445 - acc: 0.6839 - val_loss: 1.5214 - val_acc: 0.5291\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.0266 - acc: 0.6888 - val_loss: 1.5807 - val_acc: 0.5136\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.0115 - acc: 0.6961 - val_loss: 1.6034 - val_acc: 0.5141\n",
      "Experiment with L1 = 0.000000, L2 = 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 2.0249 - acc: 0.2743 - val_loss: 1.8689 - val_acc: 0.3274\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.8070 - acc: 0.3635 - val_loss: 1.7535 - val_acc: 0.3844\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.7240 - acc: 0.3961 - val_loss: 1.6958 - val_acc: 0.4009\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.6654 - acc: 0.4157 - val_loss: 1.6491 - val_acc: 0.4168\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.6191 - acc: 0.4320 - val_loss: 1.6061 - val_acc: 0.4403\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.5806 - acc: 0.4441 - val_loss: 1.5690 - val_acc: 0.4488\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.5462 - acc: 0.4572 - val_loss: 1.5490 - val_acc: 0.4521\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5184 - acc: 0.4688 - val_loss: 1.5268 - val_acc: 0.4620\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 1.4916 - acc: 0.4766 - val_loss: 1.4994 - val_acc: 0.4704\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.4669 - acc: 0.4850 - val_loss: 1.4857 - val_acc: 0.4739\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.4413 - acc: 0.4950 - val_loss: 1.5004 - val_acc: 0.4660\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.4203 - acc: 0.5008 - val_loss: 1.4702 - val_acc: 0.4782\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.3982 - acc: 0.5089 - val_loss: 1.4470 - val_acc: 0.4876\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.3769 - acc: 0.5161 - val_loss: 1.4615 - val_acc: 0.4846\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.3593 - acc: 0.5239 - val_loss: 1.4307 - val_acc: 0.4914\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.3409 - acc: 0.5270 - val_loss: 1.4094 - val_acc: 0.4966\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.3212 - acc: 0.5356 - val_loss: 1.4363 - val_acc: 0.4898\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.3039 - acc: 0.5421 - val_loss: 1.4029 - val_acc: 0.5065\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.2879 - acc: 0.5475 - val_loss: 1.3712 - val_acc: 0.5131\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.2689 - acc: 0.5529 - val_loss: 1.3736 - val_acc: 0.5104\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.2552 - acc: 0.5575 - val_loss: 1.4021 - val_acc: 0.4999\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.2404 - acc: 0.5635 - val_loss: 1.3828 - val_acc: 0.5054\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.2249 - acc: 0.5693 - val_loss: 1.3991 - val_acc: 0.5014\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.2111 - acc: 0.5715 - val_loss: 1.3762 - val_acc: 0.5123\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.1978 - acc: 0.5792 - val_loss: 1.3474 - val_acc: 0.5220\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.1807 - acc: 0.5823 - val_loss: 1.3443 - val_acc: 0.5253\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.1688 - acc: 0.5901 - val_loss: 1.3454 - val_acc: 0.5209\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.1567 - acc: 0.5930 - val_loss: 1.3800 - val_acc: 0.5154\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.1397 - acc: 0.5988 - val_loss: 1.3539 - val_acc: 0.5228\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.1262 - acc: 0.6038 - val_loss: 1.3884 - val_acc: 0.5171\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 1.1154 - acc: 0.6065 - val_loss: 1.3804 - val_acc: 0.5154\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.1034 - acc: 0.6113 - val_loss: 1.3251 - val_acc: 0.5349\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.0899 - acc: 0.6176 - val_loss: 1.3258 - val_acc: 0.5315\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.0748 - acc: 0.6241 - val_loss: 1.3375 - val_acc: 0.5286\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.0635 - acc: 0.6255 - val_loss: 1.4472 - val_acc: 0.5029\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.0509 - acc: 0.6302 - val_loss: 1.3549 - val_acc: 0.5265\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.0375 - acc: 0.6347 - val_loss: 1.3694 - val_acc: 0.5206\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.0223 - acc: 0.6406 - val_loss: 1.3927 - val_acc: 0.5127\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.0156 - acc: 0.6428 - val_loss: 1.3742 - val_acc: 0.5220\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.0027 - acc: 0.6478 - val_loss: 1.3947 - val_acc: 0.5240\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.9887 - acc: 0.6516 - val_loss: 1.3394 - val_acc: 0.5356\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.9774 - acc: 0.6561 - val_loss: 1.3468 - val_acc: 0.5238\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.9625 - acc: 0.6610 - val_loss: 1.3933 - val_acc: 0.5227\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.9526 - acc: 0.6657 - val_loss: 1.4568 - val_acc: 0.5150\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.9394 - acc: 0.6692 - val_loss: 1.3644 - val_acc: 0.5297\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.9314 - acc: 0.6723 - val_loss: 1.4026 - val_acc: 0.5307\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.9219 - acc: 0.6752 - val_loss: 1.3978 - val_acc: 0.5238\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.9065 - acc: 0.6810 - val_loss: 1.4513 - val_acc: 0.5144\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.8921 - acc: 0.6865 - val_loss: 1.5043 - val_acc: 0.5096\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.8828 - acc: 0.6891 - val_loss: 1.3900 - val_acc: 0.5307\n",
      "Experiment with L1 = 0.000000, L2 = 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 2.0346 - acc: 0.2702 - val_loss: 1.8684 - val_acc: 0.3442\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.8109 - acc: 0.3655 - val_loss: 1.7562 - val_acc: 0.3855\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.7245 - acc: 0.3955 - val_loss: 1.6976 - val_acc: 0.3984\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.6642 - acc: 0.4170 - val_loss: 1.6373 - val_acc: 0.4290\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.6164 - acc: 0.4328 - val_loss: 1.6070 - val_acc: 0.4372\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5760 - acc: 0.4465 - val_loss: 1.5701 - val_acc: 0.4472\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.5414 - acc: 0.4604 - val_loss: 1.5341 - val_acc: 0.4622\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.5107 - acc: 0.4706 - val_loss: 1.5183 - val_acc: 0.4631\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.4839 - acc: 0.4796 - val_loss: 1.4956 - val_acc: 0.4724\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.4573 - acc: 0.4883 - val_loss: 1.4841 - val_acc: 0.4736\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.4327 - acc: 0.4969 - val_loss: 1.4639 - val_acc: 0.4839\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.4093 - acc: 0.5055 - val_loss: 1.4579 - val_acc: 0.4894\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.3881 - acc: 0.5130 - val_loss: 1.4587 - val_acc: 0.4801\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.3687 - acc: 0.5190 - val_loss: 1.4489 - val_acc: 0.4903\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.3488 - acc: 0.5252 - val_loss: 1.4538 - val_acc: 0.4777\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.3314 - acc: 0.5319 - val_loss: 1.4086 - val_acc: 0.4996\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.3123 - acc: 0.5392 - val_loss: 1.4040 - val_acc: 0.5031\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.2935 - acc: 0.5443 - val_loss: 1.3921 - val_acc: 0.5057\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.2785 - acc: 0.5517 - val_loss: 1.3657 - val_acc: 0.5158\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.2599 - acc: 0.5564 - val_loss: 1.3837 - val_acc: 0.5067\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 1.2446 - acc: 0.5624 - val_loss: 1.3676 - val_acc: 0.5178\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.2307 - acc: 0.5678 - val_loss: 1.3658 - val_acc: 0.5131\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.2148 - acc: 0.5727 - val_loss: 1.3472 - val_acc: 0.5222\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.2024 - acc: 0.5751 - val_loss: 1.3749 - val_acc: 0.5160\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.1856 - acc: 0.5822 - val_loss: 1.3938 - val_acc: 0.5078\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.1714 - acc: 0.5861 - val_loss: 1.3410 - val_acc: 0.5231\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.1575 - acc: 0.5905 - val_loss: 1.3904 - val_acc: 0.5128\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.1459 - acc: 0.5937 - val_loss: 1.3476 - val_acc: 0.5211\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.1316 - acc: 0.5997 - val_loss: 1.3359 - val_acc: 0.5278\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.1149 - acc: 0.6068 - val_loss: 1.3739 - val_acc: 0.5259\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.1044 - acc: 0.6102 - val_loss: 1.3610 - val_acc: 0.5202\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.0929 - acc: 0.6166 - val_loss: 1.4167 - val_acc: 0.5052\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.0787 - acc: 0.6199 - val_loss: 1.3436 - val_acc: 0.5294\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 1.0690 - acc: 0.6239 - val_loss: 1.3915 - val_acc: 0.5199\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 1.0528 - acc: 0.6279 - val_loss: 1.3849 - val_acc: 0.5236\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.0398 - acc: 0.6317 - val_loss: 1.3731 - val_acc: 0.5214\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.0268 - acc: 0.6397 - val_loss: 1.3584 - val_acc: 0.5271\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.0160 - acc: 0.6426 - val_loss: 1.4278 - val_acc: 0.5158\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.0014 - acc: 0.6461 - val_loss: 1.3748 - val_acc: 0.5245\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.9875 - acc: 0.6508 - val_loss: 1.3496 - val_acc: 0.5294\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.9772 - acc: 0.6568 - val_loss: 1.4298 - val_acc: 0.5174\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.9655 - acc: 0.6603 - val_loss: 1.3921 - val_acc: 0.5152\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.9503 - acc: 0.6666 - val_loss: 1.4858 - val_acc: 0.5066\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.9395 - acc: 0.6681 - val_loss: 1.3705 - val_acc: 0.5355\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.9317 - acc: 0.6713 - val_loss: 1.4005 - val_acc: 0.5285\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.9199 - acc: 0.6756 - val_loss: 1.3749 - val_acc: 0.5375\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.9075 - acc: 0.6796 - val_loss: 1.3593 - val_acc: 0.5371\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.8932 - acc: 0.6851 - val_loss: 1.3938 - val_acc: 0.5310\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.8837 - acc: 0.6891 - val_loss: 1.3685 - val_acc: 0.5431\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.8725 - acc: 0.6932 - val_loss: 1.3656 - val_acc: 0.5422\n",
      "Experiment with L1 = 0.000000, L2 = 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 2.0326 - acc: 0.2742 - val_loss: 1.8794 - val_acc: 0.3268\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.8085 - acc: 0.3661 - val_loss: 1.7662 - val_acc: 0.3817\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 1.7194 - acc: 0.4007 - val_loss: 1.6880 - val_acc: 0.4069\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.6592 - acc: 0.4200 - val_loss: 1.6349 - val_acc: 0.4263\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.6131 - acc: 0.4354 - val_loss: 1.6037 - val_acc: 0.4362\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.5731 - acc: 0.4505 - val_loss: 1.5711 - val_acc: 0.4427\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.5407 - acc: 0.4614 - val_loss: 1.5499 - val_acc: 0.4505\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.5129 - acc: 0.4708 - val_loss: 1.5406 - val_acc: 0.4588\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.4858 - acc: 0.4802 - val_loss: 1.4987 - val_acc: 0.4688\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.4604 - acc: 0.4895 - val_loss: 1.5002 - val_acc: 0.4677\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.4367 - acc: 0.4969 - val_loss: 1.4713 - val_acc: 0.4798\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.4152 - acc: 0.5046 - val_loss: 1.4472 - val_acc: 0.4878\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.3929 - acc: 0.5138 - val_loss: 1.4432 - val_acc: 0.4904\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 1.3740 - acc: 0.5177 - val_loss: 1.4473 - val_acc: 0.4881\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.3550 - acc: 0.5249 - val_loss: 1.4297 - val_acc: 0.4927\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 4s 74us/step - loss: 1.3346 - acc: 0.5320 - val_loss: 1.4022 - val_acc: 0.5037\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 4s 74us/step - loss: 1.3167 - acc: 0.5371 - val_loss: 1.4192 - val_acc: 0.4981\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.3010 - acc: 0.5449 - val_loss: 1.3984 - val_acc: 0.5065\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.2849 - acc: 0.5500 - val_loss: 1.4011 - val_acc: 0.5041\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.2678 - acc: 0.5547 - val_loss: 1.4046 - val_acc: 0.4965\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.2514 - acc: 0.5615 - val_loss: 1.3782 - val_acc: 0.5126\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 1.2378 - acc: 0.5658 - val_loss: 1.3942 - val_acc: 0.5063\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.2221 - acc: 0.5713 - val_loss: 1.3617 - val_acc: 0.5203\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.2088 - acc: 0.5762 - val_loss: 1.3607 - val_acc: 0.5164\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.1935 - acc: 0.5802 - val_loss: 1.3574 - val_acc: 0.5184\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.1777 - acc: 0.5869 - val_loss: 1.3600 - val_acc: 0.5146\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.1670 - acc: 0.5894 - val_loss: 1.3691 - val_acc: 0.5155\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.1515 - acc: 0.5942 - val_loss: 1.3435 - val_acc: 0.5238\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.1374 - acc: 0.5996 - val_loss: 1.3354 - val_acc: 0.5280\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.1242 - acc: 0.6062 - val_loss: 1.3571 - val_acc: 0.5216\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.1117 - acc: 0.6095 - val_loss: 1.3467 - val_acc: 0.5257\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 4s 74us/step - loss: 1.0999 - acc: 0.6144 - val_loss: 1.3323 - val_acc: 0.5284\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 4s 74us/step - loss: 1.0843 - acc: 0.6190 - val_loss: 1.4331 - val_acc: 0.5021\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 4s 73us/step - loss: 1.0750 - acc: 0.6232 - val_loss: 1.3768 - val_acc: 0.5234\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 1.0619 - acc: 0.6276 - val_loss: 1.3573 - val_acc: 0.5235\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.0489 - acc: 0.6325 - val_loss: 1.4976 - val_acc: 0.4866\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.0358 - acc: 0.6371 - val_loss: 1.3853 - val_acc: 0.5223\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.0211 - acc: 0.6421 - val_loss: 1.3945 - val_acc: 0.5240\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 1.0100 - acc: 0.6455 - val_loss: 1.3472 - val_acc: 0.5312\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.9965 - acc: 0.6489 - val_loss: 1.3925 - val_acc: 0.5238\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.9835 - acc: 0.6564 - val_loss: 1.4040 - val_acc: 0.5164\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 0.9763 - acc: 0.6580 - val_loss: 1.3650 - val_acc: 0.5245\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 0.9624 - acc: 0.6626 - val_loss: 1.3899 - val_acc: 0.5231\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 4s 75us/step - loss: 0.9470 - acc: 0.6678 - val_loss: 1.4069 - val_acc: 0.5171\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 0.9351 - acc: 0.6703 - val_loss: 1.4514 - val_acc: 0.5056\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 4s 73us/step - loss: 0.9252 - acc: 0.6759 - val_loss: 1.4229 - val_acc: 0.5227\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.9144 - acc: 0.6818 - val_loss: 1.3827 - val_acc: 0.5296\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.8987 - acc: 0.6836 - val_loss: 1.3875 - val_acc: 0.5244\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.8860 - acc: 0.6881 - val_loss: 1.3658 - val_acc: 0.5350\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.8738 - acc: 0.6958 - val_loss: 1.3784 - val_acc: 0.5331\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for l1r, l2r in itertools.product(L1_EXP, L2_EXP):\n",
    "    keras.backend.clear_session() # 把舊的 Graph 清掉\n",
    "    print(\"Experiment with L1 = %.6f, L2 = %.6f\" % (l1r, l2r))\n",
    "    model = build_mlp(input_shape=x_train.shape[1:], l1_ratio=l1r, l2_ratio=l2r)\n",
    "    model.summary()\n",
    "    optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "    model.fit(x_train, y_train, \n",
    "              epochs=EPOCHS, \n",
    "              batch_size=BATCH_SIZE, \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True)\n",
    "    \n",
    "    # Collect results\n",
    "    train_loss = model.history.history[\"loss\"]\n",
    "    valid_loss = model.history.history[\"val_loss\"]\n",
    "    train_acc = model.history.history[\"acc\"]\n",
    "    valid_acc = model.history.history[\"val_acc\"]\n",
    "    \n",
    "    exp_name_tag = \"exp-l1-%s-l2-%s\" % (str(l1r), str(l2r))\n",
    "    results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                             'valid-loss': valid_loss,\n",
    "                             'train-acc': train_acc,\n",
    "                             'valid-acc': valid_acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd0AAAF1CAYAAACtcjDtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3XlcVNX7wPHPZdgUQUHEBVyRVFAkxd3ct8wlTc0sl8zSbLOyzL79Km3TSlvdSktNU9Myzcoll8p9wRUQV1BcWUVkh/P74whIooICM8Dzfr3ua+bOvXPnGS2fOeeecx5DKYUQQgghCp+VuQMQQgghSgtJukIIIUQRkaQrhBBCFBFJukIIIUQRkaQrhBBCFBFJukIIIUQRkaQrhBBCFBFJukJYMMMwQg3D6GLuOIQQBUOSrhBCCFFEJOkKUQwZhvG0YRgnDMOINgxjtWEY1a6/bhiG8ZlhGJcNw7hiGMYhwzAaXj/W0zCMIMMwrhqGcc4wjPHm/RZClD6SdIUoZgzD6AR8BAwCqgJhwNLrh7sB7YD7gArAo0DU9WPzgNFKKUegIbCpCMMWQgDW5g5ACJFvjwPfKaUCAAzDmAjEGIZRC0gFHIH6wG6lVPAN70sFvA3DOKiUigFiijRqIYS0dIUohqqhW7cAKKXi0a1Zd6XUJuBrYAZwyTCMbwzDcLp+6iNATyDMMIy/DcNoVcRxC1HqSdIVovg5D9TM3DEMwwGoCJwDUEp9qZRqCvigu5lfu/76HqVUX8AN+BX4qYjjFqLUk6QrhOWzMQzDPnNDJ8snDcPwMwzDDvgQ2KWUCjUMo5lhGC0Mw7ABrgFJQLphGLaGYTxuGEZ5pVQqEAekm+0bCVFKSdIVwvL9ASTesD0A/B/wM3AB8AQGXz/XCfgWfb82DN3t/On1Y0OBUMMw4oAxwBNFFL8Q4jpDitgLIYQQRUNaukIIIUQRydOUIcMwQoGr6HtAaUop/8IMSgghhCiJ8jNPt6NSKrLQIhFCCCFKOOleFkIIIYpIXpOuAtYbhrHPMIxnCjMgIYQQoqTKa/dyG6XUecMw3IANhmEcVUr9c+MJ15PxMwAODg5N69evX8ChiiyXLkF4OPj6go0NXL4MZ89Co0Zga2vu6IQQotTZt29fpFKq0p3Oy/eUIcMw3gXilVKf3uocf39/tXfv3nxdV+TDvn3g7w+LF8OQIRAQAE2bwo8/wmOPmTs6IYQodQzD2JeXQcZ37F42DMPBMAzHzOfoKiZH7j1Ecdf8/KB8ediyRe/7+kK5crB1q1nDEkIIcXt56V6uDKw0DCPz/B+VUmsLNSpxeyYTtGsHmzfrfWtraNlSkq4QQli4OyZdpdQpoHERxCLy47HHYNcuSEvTSbdtW5g0CWJjoUIFc0cnhBAiF1JPt7h67LGc92/btwel4O+/oW9f88UlhLgnqamphIeHk5SUZO5QRC7s7e3x8PDAxsbmrt4vSbc4S02Fc+egVi1o1QocHGD9ekm6QhRj4eHhODo6UqtWLa7f1hMWQilFVFQU4eHh1K5d+66uIYtjFGdPPAGdO+vndnbQoYNOukKIYispKYmKFStKwrVAhmFQsWLFe+qFkKRbnLVuDadOwZkzer9bNzhxQr8mhCi2JOFarnv9u5GkW5x17KgfM6cOdeumHzdsMEs4QgiRm9DQUBo2bAjAhg0baNq0KY0aNaJp06Zs2rTplu/76KOPqFu3LvXq1WPdunW5nnP69GlatGiBl5cXjz76KCkpKQD8888/NGnSBGtra1asWFHwX+ouSdItzho2hIoVs6cO1asH1atLF7MQwmK5urry22+/cfjwYRYsWMDQoUNzPS8oKIilS5cSGBjI2rVrGTt2LOnp6TedN2HCBF5++WWOHz+Os7Mz8+bNA6BGjRrMnz+fIUOGFOr3yS9JusWZlZUetZyZdA1Dt3Y3btRTiYQQ4i4sWrSI5s2b4+fnx+jRowkLC8PLy4vIyEgyMjJ44IEHWL9+PaGhodSvX5/hw4fj6+vLgAEDSEhIuO2177//fqpVqwaAj48PSUlJJCcn33TeqlWrGDx4MHZ2dtSuXZu6deuye/fuHOcopdi0aRMDBgwAYPjw4fz6668A1KpVC19fX6ysLCvNyejl4u611yAxUU8Xyky68+bBnj16RLMQovgaNw4OHCjYa/r5weef3/JwcHAwy5YtY9u2bdjY2DB27Fj+/vtvJkyYwJgxY2jRogXe3t5069aN0NBQQkJCmDdvHm3atGHkyJHMnDmT8ePH5ymUn3/+mfvvvx87O7ubjp07d46WLVtm7Xt4eHDu3Lkc50RFRVGhQgWsra1veY6lsayfACL/WrbU93Yzb+537qyfSxezEOIubNy4kX379tGsWTP8/PzYuHEjp06dYtSoUVy9epXZs2fz6afZS+9Xr16dNm3aAPDEE0+wNY8r4wUGBjJhwgTmzJmT6/Hc6gL8dxBTXs6xNNLSLQn++UdXHho4UN/j9ffXSfedd8wdmRDiXtymRVpYlFIMHz6cjz76KMfrCQkJhIeHAxAfH4+joyNwc5IzDINdu3YxevRoACZPnoyvr2+Oc8LDw+nXrx8LFy7E09MTgJUrVzJp0iQA5s6di4eHB2fPns3xnsxu6Uyurq7ExsaSlpaGtbV1rudYGmnplgRffQXjx+suZtBdzLt26SUhhRAiHzp37syKFSu4fPkyANHR0YSFhTFhwgQef/xxJk+ezNNPP511/pkzZ9ixYwcAS5YsoW3btrRo0YIDBw5w4MAB+vTpk+P6sbGxPPTQQ3z00UdZLWSAfv36Zb3H39+fPn36sHTpUpKTkzl9+jTHjx+nefPmOa5lGAYdO3bMGp28YMEC+lr44kCSdEuCjh31XN3Tp/V+t26Qnp49wEoIIfLI29ub999/n27duuHr60vXrl0JDQ1lz549WYnX1taW77//HoAGDRqwYMECfH19iY6O5tlnn73t9b/++mtOnDjBe++9h5+fH35+flkJ/kY+Pj4MGjQIb29vevTowYwZMzCZTAD07NmT8+fPAzB16lSmT59O3bp1iYqK4qmnngJgz549eHh4sHz5ckaPHo2Pj09B/jHdtXzX080LqadbxIKCwMdHD6AaORJSUnQ38xNPwKxZ5o5OCJEPwcHBNGjQwNxh5EloaCi9evXiyJHSVe01t7+jAqunK4qBBg3AzS27ZWtrq1u/MphKCCEsiiTdksAw9LrLAQHZr3XrppeDPHnSbGEJIUq2WrVqlbpW7r2SpFtSzJwJhw5l72cuCSmtXSGEsBiSdEuKihXh+iADALy8oGZNSbpCCGFBJOmWJNOmwfWRe1mrU23apOvuCiGEMDtJuiVJRAQsXAhxcXq/Wzf9/D/rlQohhDAPSbolSa9eutBBZgmsTp10UQTpYhZCmJGU9ssmSbckadkSXFxgzRq97+ICzZpJ0hVCWAwp7SdKDmtrePBB+OMPvSIV6C7m3bshJsa8sQkhig0p7Vd4LCsace8GDYIePbLv63bvDhkZekCVEKL46dDh5m3mTH0sISH34/Pn6+ORkTcfu4MbS/sdOHAAk8mUo7TftGnTskr7AYSEhPDMM89w6NAhnJycmJkZWx7cqbRf9erVs/altJ+wTH36wA8/gLOz3m/eHJycpItZCJEnUtqvcElpv5JIKb0alacn2NjoAVXr1mUXuhdCFB9bttz6WNmytz/u6nr747mQ0n6FS1q6JdGcOVC3rq48BPq+blgYHD9u3riEEBZPSvsVLkm6JVHHjvrx99/1oywJKYTIIyntV7iktF9JpJReBrJevezE6+mpy/+tXm3e2IQQtyWl/SyflPYTORmGXihj40a4dk2/1q2bLv13feK4EEKIoidJt6Tq1QuSk3XiBZ104+Nh507zxiWEKDGktF/+SdItqdq1g2XLoH17vd+pk148I7O7WQghRJGTpFtS2drqhTLKl9f75cvrAVa//KLv+QohhChyknRLsuho+OQTCA7W+/37w4kTEBho3riEEKKUkqRbkqWlwYQJsHy53u/bVw+yWrnSvHEJIUQpJUm3JHNzgxYtsqsOVa0KrVrpLmYhhCgi5ijtl5yczKOPPkrdunVp0aIFoaGhd7zuyJEjcXNzy4q1MEjSLel69YI9e+DiRb3fvz8cOACnT5s3LiFEqVRUpf3mzZuHs7MzJ06c4OWXX2bChAl3vO6IESNYu3ZtIX1zTZJuSderl3784w/92K+ffpQuZiHELZSE0n6rVq1i+PDhAAwYMICNGzeilLrtddu1a4eLi8u9/eHdgRQ8KOl8faFOHb32MujnjRvrLuZXXjFvbEKI2xq3dhwHLh4o0Gv6VfHj8x6f3/L4jaX9bGxsGDt2bI7Sfi1atMgq7RcaGkpISAjz5s2jTZs2jBw5kpkzZzJ+/Pg8xXKn0n4tW7bM2s9vab8bSwNaW1tTvnx5oqKi8nTdwiQt3ZLOMODoUbhevQPQXczbt2d3OQshxHUlpbTfrY6ZuxygtHRLAxsb/ZhZ2q9fP3jnHVi1Cq6X3xJCWJ7btUgLS0kp7Zf5fg8PD9LS0rhy5QouLi55um5hkpZuaaAU9OiR3Z3csKEu/SejmIUQ/1FSSvv16dOHBQsWALBixQo6deqEYRh5um6hUkoV+Na0aVMlLEyvXkrVrq1URobef+01paytlYqJMW9cQogcgoKCzB2CWrp0qWrcuLFq1KiRatKkidqyZYtq0aKFSktLU0op1a9fP/Xdd9+p06dPqwYNGqjRo0erRo0aqf79+6tr167ddL3Tp08rHx8fpZRS7733nipbtqxq3Lhx1nbp0qVc43j//fdVnTp11H333af++OOPrNcffPBBde7cOaWUUidPnlTNmjVTnp6easCAASopKUkppVRiYqIaMGCA8vT0VM2aNVMnT56843UHDx6sqlSpoqytrZW7u7uaO3durnHl9ncE7FV5yI9S2q+0mDMHxozRq1F5e+vCB61awQ8/wBNPmDs6IcR1UtrP8klpP3FnDz2kHzOnCjVvDtWqydQhIYQoQpJ0SwsPD2jbFn78Ud/jtbKChx+GP/+EO8yrE0KI3Ehpv/yTpFuajB+vRytnrurSvz8kJsItllcTQghRsGTKUGlyfVRflnbtwMVFdzFnrlQlhBCi0EhLt7S5ckUPnkpP1/N3e/eG336D1FRzRyaEECWeJN3SZu1aGDYM/v5b7/fvD7GxsGWLWcMSQojSQJJuadO7N5QrB4sX6/2uXcHBQRbKEEIUGintl02SbmlTtiw88gisWAFJSVCmDDz4IPz6K2RkmDs6IUQJJ6X9ROnz+OMQF5dd3L5/f138YOdO88YlhLAIUtqv8Mjo5dKoUyeoUkUn2QED9MIZtra6i7l1a3NHJ4S4QYf5HW56bZDPIMY2G0tCagI9F/e86fgIvxGM8BtBZEIkA34akOPYlhFbbvt5UtqvcElLtzQymeDIEcgsz+XkBJ0766lDhbAsqBCi+JDSfoVLWrqlVcWK+jGz3F///vD003DokC5yL4SwCLdrmZa1KXvb465lXe/Ysv0vJaX9CpW0dEuzN97IXpO5Tx+9NKSMYhaiVJPSfoUsL6WIrjfHTcB+YM2dzpXSfsXE5MlKgVJnzuj9Dh2Uuu++7PJ/QogiJ6X9spXq0n6GYbwC+ANOSqletztXSvsVEydP6mL2U6fC66/Dd9/BU0/Bjh1ww0ADIUTRkdJ+lq/QS/sZhuEBPATMvasIhWXy9NTJddEivT9woJ7HO3++WcMSQoiSKq/3dD8HXgdk9YSS5okn4PBhvTk66oUzli7V1YeEEOI2pLRf/t0x6RqG0Qu4rJTad4fznjEMY69hGHsjIiIKLEBRyAYNgokTwdlZ7w8frosirF5t3riEEKIEyktLtw3QxzCMUGAp0MkwjEX/PUkp9Y1Syl8p5V+pUqUCDlMUmkqV4MMPdZF7gI4doXp16WIWQohCcMekq5SaqJTyUErVAgYDm5RSTxR6ZKLopKXBn39CYKCeNjR8OKxfD+fPmzsyIYQoUWSeroDkZD2I6osv9P6wYbr4waKbOjSEEELcg3wlXaXUljtNFxLFkIMD9OsHy5frBOzlBW3a6C5mWRZSCHGP7qa0X1RUFB07dqRcuXI8//zzd/W5CxYswMvLCy8vr6yFMkAv4tGoUSN8fX3p0aMHkZGRd3X9uyEtXaE9/rguZv/nn3p/xAgIDoY9e8walhCiZMlraT97e3vee++9HOs850d0dDSTJk1i165d7N69m0mTJhETE0NaWhovvfQSmzdv5tChQ/j6+vL111/fy1fKF0m6QuvSBdzc4Icf9P7AgWBvDzf8OhRClA6WUNrPwcGBtm3bYm9vf9Ox9evX06pVK5o0acLAgQOJj4+/6Zx169bRtWtXXFxccHZ2pmvXrqxduzZrZahr166hlCIuLq5I116WggdCs7bWrd3VqyElBcqX10UQliyBadN0AhZCFKlx4+DAgYK9pp8ffP75rY9bSmm/W4mMjOT999/nr7/+wsHBgalTpzJ9+nTefvvtHOfdWNoPskv42djYMGvWLBo1aoSDgwNeXl7MmDEjz59/r6SlK7JNngwhIbq2Lugu5pgY+O03s4YlhCg6llLa71Z27txJUFAQbdq0wc/PjwULFhAWFnbTebktcWwYBqmpqcyaNYv9+/dz/vx5fH19b6qoVJikpSuylSunH1NTdcu3Uydwd9ddzAMHmjc2IUqh27VIC4uykNJ+/v65L2OslKJr164sWbIkx+v//UwPDw+2bNmS4zM7dOjAgetdB5mfO2jQIKZMmZKHP5mCIS1dkdOePXpxjF27dLH7YcNg7Vq4cMHckQkhioCllPa7lZYtW7Jt2zZOnDgB6B8Dx44du+kzu3fvzvr164mJiSEmJob169fTvXt33N3dCQoKInPlxA0bNhRtgYm8lCLK7yal/YqxuDilHByUeuopvX/0qC7/98kn5o1LiFJCSvtlq1mzpnJ2dlYODg7K3d1dBQYGKqWU2rhxo/L391eNGjVSjRo1UqtWrcr1/fPmzVOenp7K09NTfffdd1mvz5o1S9WvX181atRI9erVS0VGRubrz6dISvvlh5T2K+aeegqWLdOtW0dHaNUK4uPh0CH4T1eSEKJgSWk/y1fopf1EKTNqFFy7Bj/9pPdHjIAjRyAgwKxhCSFEcSdJV9ysZUto0ADmXi+f/OijYGcnRRCEEDlIab/8k6QrbmYY8Omn8MEHer9CBXj4YfjxR71MpBBCiLsiSVfkrmdPPWUo04gREB0Nv/9utpCEEKK4k6Qrbu3kSZgwQa9Q1bUrVKsmXcxCCHEPJOmKWzt+HD7+WC8NaTLB0KHwxx9wfYK8EEKI/JGkK26ta1e9UEbmgKrRo3Wpv5kzzRuXEKJYkdJ+2STpilszmeDJJ2H9ejhzBmrXhj594JtvIDHR3NEJIYohKe0nxO08+aR+/P57/fjSSxAVBYsXmy8mIUShktJ+hUeSrri9WrWgb189mAqgfXvw9YUvv9RdzUKIQtWhw81b5h2ehITcj2eOd4yMvPnYndxY2u/AgQOYTKYcpf2mTZuWVdoPICQkhGeeeYZDhw7h5OTEzHzcfrrX0n4BAQH4+/szffr0m87LS2m/atWqERQUxFNPPZXnz79XknTFnf3yS/acXcPQrd3Dh+GGCh5CiJJBSvsVLintJ+7MMHSrNixMt3yHDNFTib74Ajp2NHd0QpRot/ttW7bs7Y+7uub/t7GS0n6FKy9VEfK7SZWhEuijj5SytVUqIkLv/+9/ShmGUidPmjcuIUoYc1cZCgwMVHXr1s2q/BMVFaVCQ0PV888/rz744AO1aNEi9dBDDymldPUgQG3fvl0ppdSoUaPUp59+etM1b6wyFBMTo3x9fdWKFSvyFM/333+vnnvuuaz9y5cvq+rVq6vjx48rpZS6du2aCgkJuel9UVFRqlatWio6OlpFR0erWrVqqaioKHXu3DlVpUoVdfnyZaWUUm+99ZZ65ZVX8vrHo5S6typDknRF3hw6pP9z+ewzvX/unFLW1kq9/LJ54xKihDF30lVKSvvdiZT2E0WjeXM9cuPwYd3lPGSIXhYyPFyXABRC3DMp7Wf5pLSfKBpjxkBgIGzcqPdffBHi4uCGSedCCCFuTZKuyLvHH4eqVWH2bL3fsqVu/X75JWRkmDc2IUSRk9J++SdJV+SdnZ3uTl64MPu1l17SazSvXWu+uIQQopiQpCvy5/779TyFzLEAAwbo1u8XX5g3LiGEKAYk6Yr827kTGjTQpf9sbWHsWL0+c3CwuSMTQgiLJklX5F/NmnD6NEybpvdHj9Zdz199Zd64hBDCwknSFflXtSoMG6aLIFy+DJUq6elDCxZATIy5oxNCWBhzlfbr0aMHFSpUoFevXjlef/zxx6lXrx4NGzZk5MiRpKam3tX174YkXXF3xo+H5OTs1u1LL+k5vPPmmTcuIYRFK6rSfgCvvfYaP/zww02vP/744xw9epTDhw+TmJjI3Mya4UVAkq64O/XqwcMPw4wZEB8PjRvrCkRffw1paeaOTghxD0pCaT+Azp07Z60RfaOePXtiGAaGYdC8efOsNaWLghQ8EHfvnXf03N0yZfT+Sy9B//6wYgUMHmze2IQoAY4fH0d8/IECvWa5cn54eX1+y+M3lvazsbFh7NixOUr7tWjRIqu0X2hoKCEhIcybN482bdowcuRIZs6cyfjx4/MUy72W9nNwcGDq1KlMnz6dt99+O8/XyJSamsoPP/zAF0U4+0KSrrh7jRvrLVOfPuDtDZMnw8CBYDKZLzYhxF25sbQfQGJiIm5ubrz77rssX76c2bNnZ1XqgZtL+3355Zd5SrqZpf3Wr1+fr/huLO0HkJKSQqtWrfJ1jUxjx46lXbt2PPDAA3f1/rshSVfcm+RkmDIFfHz0nN1334VBg2DZMj24Sghx127XIi0sqoSU9uvTp89tv+ekSZOIiIjIdz3fe5aXqgj53aTKUCmSkaFUw4ZK+fgolZ6ut0aNlLrvPqVSU80dnRDFjrmrDJWU0n6ZNm/enBVvpm+//Va1atVKJSQk5CmG/5LSfsK8Fi7U/yn99pve/+UXvb9ggXnjEqIYMnfSVarklPZr27atcnV1Vfb29srd3V2tXbtWKaWUyWRSderUyfr8SZMm5evPR0r7CfNKTYW6daFGDfj3X71EZNOmugLR0aNgLXcxhMgrKe1n+aS0nzAvGxt45RXYuhW2b9e1dt99Vy8TmcscOSGEKK0k6YqCMWqUniZUrpze791bt3YnT9YtYSFEiSOl/fJPkq4oGA4OsGQJZI5SNAydcENDYf58c0YmhBAWQ5KuKFhnzsAnn+jnDz4ILVrA++9DSop54xJCCAsgSVcUrOXL4fXXYd063dqdNEkn4u++M3dkQghhdpJ0RcF64QU9kvmVV/QazN26QevW8MEHkJRk7uiEEMKsJOmKgmVrq7uXg4Lgm2+y7+2Gh0MRVvIQQlgOKe2XTZKuKHh9+0LHjvD227q+bqdO0K4dfPghJCaaOzohhBlJaT8hCpphwGef6YpDGRnZ93YvXNCtXyGERZPSfoVHkq4oHI0b6wRbsaLe79BBt34/+kgXuxdC5Mn+/R1u2s6dmwlAenpCrscvXJgPQEpK5E3H7uTG0n4HDhzAZDLlKO03bdq0rNJ+ACEhITzzzDMcOnQIJycnZs6cmefvdq+l/QICAvD392f69Ol5fv+NMkv79ejR467efzck6YrCtWcPvPWWfj5pEly6pAvdCyEs0o2l/fz8/Ni4cSOnTp1i1KhRXL16ldmzZ+fo8v1vab+tW7fm6XMyS/vlt8rPjaX9/Pz8WLBgAWFhYfm6RiYp7SdKnk2b9Mjljh2hc2fo2VPP2x06FKpWNXd0Qli8++/fcstjJlPZ2x63tXW97fHcKCntV7jyUhUhv5tUGRJZEhOVqlVLl/tLS1Pq2DGlbG2VGjbM3JEJYZHMXWVISvvdmZT2E5Zt+XL9n9qcOXr/jTf0/rZt5o1LCAtk7qSrlJT2uxMp7Scsm1LQvr0u83f8OJhMUL8+VK4Mu3frfSEEIKX9igMp7ScsW+YUopdfBjs7XYnok08gIADmzTN3dEIIUWQk6Yqi0bQpTJwImXPuBg/WC2a8+SZER5s3NiHEXZHSfvknSVcUrZUr4foIQ778Uq9Y9fbb5o1JCCGKiCRdUbTCwvSiGcuW6QU0nn0WZs2CgwfNHZkQFqMwxtqIgnGvfzd3TLqGYdgbhrHbMIyDhmEEGoYx6Z4+UZRuL7wAzZrBiy9CVJQuhuDsrF+Xf2iEwN7enqioKEm8FkgpRVRUVK5LU+ZVXhbHSAY6KaXiDcOwAbYahvGnUmrnXX+qKL1MJl1tqGlTePVVmD9fF0IYPRqWLoXHHjN3hEKYlYeHB+Hh4URERJg7FJELe3t7PDw87vr9+ZoyZBhGWWAr8KxSatetzpMpQ+KO3npLr1S1ezc0aQLNm8PFixASokc3CyFEMVKgU4YMwzAZhnEAuAxsyC3hGobxjGEYew3D2Cu/0MQdvfUWrFgB/v669fv113D+vE7EQghRQuW3pVsBWAm8oJS65ThxaemKfImLAycnGD4cliyBwEDw8jJ3VEIIkWeFsjiGUioW2AIUXR0kUbJt2gTVq8PevTB1qp7HK4OqhBAlVF5GL1e63sLFMIwyQBfgaGEHJkqJpk3BwQFGjdK1dz/8ENat04OthBCihMlLS7cqsNkwjEPAHvQ93TWFG5YoNcqXh5kz9TzdadNg7Fjo0kUvGXnihLmjE0KIAiUFD4RlGDAA1qyBw4ehTBlo1AgaNIB//gFrKfsshLBsUvBAFC9ffQVly8Kff4KHh2797tgBH39s7siEEKLASBNCWIaqVeHYMXB11fuPPQarV8M770CPHnourxBCFHPS0hWWIzPhbtuma+/OmKFr7j7xBCQmmjc2IYQoAJJ0hWVJSoJBg6B/f7C1he+/h+BgXRZQCCGKOUm6wrLY28PChXo5yKef1iOZX3gBvvgCNm40d3RCCHFPJOkKy9O5M7z/vi6A8PXXMGUK1K8PI0bo+rtCCFFMSdIVlmnCBOjTB155BU6ehB9+0AURnn/e3JEJIcRdk6QrLJOVFSxExDzrAAAgAElEQVRYAJ9+Cj4+ujDCO+/Ajz/qFrAQQhRDsjiGKB4uXNDF7jt21COb9++HWrXMHZUQQgCyOIYoSS5dAl9fePddWLRIF0Po1w8SEswdmRBC5IskXWH5KleGRx7RVYgOH9ZdzAcPwjPPSDUiIUSxIklXFA9ffKHv6w4frmvtvvceLF6sXxdCiGJCkq4oHuzsYMUKXfzgkUf03N1+/WD8eNi82dzRCSFEnkjSFcVHzZqwZAnUq6eT74IFcN99egWrsDBzRyeEEHckSVcUL926wfLluiKRyQQrV0JKil42UtZnFkJYOEm6oniKjoZWreDXX/W93YAAGDNGBlYJISyaJF1RPFWoAN7e8MYbcPUqTJqk12z+6itzRyaEELckSVcUT1ZWMH8+PPCAXpO5XTvo21cvG/n33+aOTgghciVJVxRfdna6e7l2bX1P9623oG5dGDhQBlYJISySJF1RvLm4wJ9/QtOmehGNX3/VA6u6ddMrWQkhhAWRpCuKv9q1YcMGqF5dTyH65RcID9eJNzra3NEJIUQWSbqi5FAKHntMr1L188+6MELPnnqglRBCWABJuqLkMAw9oGr1ar1wxqJFsHevHmAlc3iFEBbA2twBCFGgnnsOrl2DCRMgMhJmzYLRo/XgqpUrwcbG3BEKIUoxSbqi5Hn9dahUCZ5+Wrd+Z86EZ5+FoUP1Qhomk7kjFEKUUpJ0Rcn05JM68To7Q5s2+r7u669DuXLwzTd6nq8QQhQxSbqi5OrVK/u5vb2uv/vNNzrxfvaZbgULIUQRkqQrSr4rV+Djj3Vrd8AAPbq5TBn48ENJvEKIIiV9bKLkK18etm2DKlVgzRo9f3fKFH2fNz3d3NEJIUoRSbqidKhRA7ZuhcaN4a+/oHt3mDNHz+tNTjZ3dEKIUkKSrig9XF1h40Z48EHdzfzpp7o2b69eEB9v7uiEEKWA3NMVpYuDg148wzD0duoUzJ4NnTvD77/rxCyEEIVEWrqi9LGy0gk3IwN27NCv7dsHbdvC2bPmjU0IUaJJ0hWll5WVrr07dKgeUHXiBLRooddsFkKIQiBJV5Rujo4wf75eqcreHi5ehNatYc8ec0cmhCiBJOkKATBkCBw6BBMn6ilGHTrA0qXmjkoIUcJI0hUiU5068MEH+j5v3bp6OtGLL0JqqrkjE0KUEJJ0hfivKlVgzBj9/KuvoFMnuHTJvDEJIUoESbpC5ObZZ/W9XsOA7dvBzw927jR3VEKIYk6SrhC3Mnw4rFihRzlHR8MDD+g5vUqZOzIhRDElSVeI2+nfXy+a0aeP7mZ+9ll46ilITDR3ZEKIYkiSrhB30q2bXi7yjz/g5Zfh++/1QhrHj5s7MiFEMSNJV4i8Mpng4EFwdtYJ188PZszQK1sJIUQeSNIVIj+++krX4rWyAnd3eP55XbFIlo8UQuSBJF0h8sPbW5cIbNJEt3atrPR+o0awcKEMshJC3JYkXSHyq3Zt2LRJr9H85puwf79OusOHQ8OGcOSIuSMUQlgoSbpC3K169eC996B+fdiyRbd+g4J0Am7VSi8rKYQQN7D4pJuQmsCVpCvmDkOI2zOZdHnANWvAzU0vpHH//foesBBCXGfRSTcpLQnfWb688dcb5g5FiLx56CEID4c3rv83+9prMHmyzOsVQgAWnnTtre3p6dWTbwK+4dAl6aoTxYSNDXz0EZw+DX37wjvvQNWq8MknMtBKiFLOopMuwLsd3qWCfQXGrR2Hkn+wRHFSowYsWwarVkFCArz+ur7/KwOthCi1LD7pupRxYXKHyWwO3cyvR381dzhC5F+fPnoer48PHDumB1o9+yzExpo7MiFEEbP4pAsw2n80PpV8GL9hPElpSeYOR4j8q1xZj2Z+9109t3f2bKhVS9/vleQrRKlRLJKutZU1n3X/jFMxp/h85+fmDkeIu2Nlpe/vbtsG06dD+/Z638NDP8bEmDtCIUQhMwrjPqm/v7/au3dvgV+379K+bDq9iWPPH6OqY9UCv74QRe799+H//k8/L1MGXnlFby4u5o1LCJEvhmHsU0r53+m8YtHSzfRp109JTkvmf5v+Z+5QhCgYr76qiyZUraqnFX3wAVSrBhMnQmSkuaMTQhSwOyZdwzCqG4ax2TCMYMMwAg3DeKkoAssUF3eNiAjd7eZV0YuXWrzE9we+Z+/5gm9JC1HkypSBsWMhLAwWLIA6dcDeHqZMgZo1YcwYCA42d5RCiAKSl5ZuGvCqUqoB0BJ4zjAM78INS0tISGL9eh9WrZqQ9dpb7d7CzcFNphCJksXGBoYN00UUAgP1tKK+fWHOHF1koXVr+P13KSMoRDF3x6SrlLqglAq4/vwqEAy4F3ZgAGXL2nPlysPUrj2PffsCAShvX54POn3AtrPbWBa4rCjCEKLoZJYM9PGBTz+FgQPB2hp27IBevXQ39McfQ1ycuSMVQtyFfN3TNQyjFnA/sCuXY88YhrHXMIy9ERERBRMd4NCwNYmJ5dix++WsxXye9HsSvyp+vLbhNRJSEwrss4SwKNWqwU8/waVLMG2aTsaXL8OECfr52LG6VSyEKDbynHQNwygH/AyMU0rd9DNbKfWNUspfKeVfqVKlAguwo097fg9sS8MGG5gwYxJKKUxWJr7o8QXhceF8su2TAvssISySi4se0Xz2rC6qsHs39Oun5/o2bKjnAI8Zo+8LCyEsWp6mDBmGYQOsAdYppabf6fyCnjJ05VoM6/7wJfaqE/86tmRuv5nYWdsxaPkg1hxbQ8jzIVQvX73APk+IYuHzz2HuXD3QKvNeb506ekBWmzZ6nWerYjVBQYhiq8CmDBmGYQDzgOC8JNzCUN7BGRfnj7ivThAXt19kVcgqAD7u+jEZKoPn/3xeVqoSpc+4cXrAVWKibvXef7+ucPTAA7rWr7MzdOumB2OFh5s7WiEEeetebgMMBToZhnHg+tazkOO6SefOQ7h0qQlPtzrCAy69AaharirvdXyP1SGruX/O/ewKv+lWsxAln60tjB4NAQEQFQXffae7pOPiYMMG3fVcvboutvDnn+aOVohSrVitSHX48Gaiojqxf/8UOg95kF4/9uK7vt+RnpHO0789zbmr53i11atM6jCJMjZlCvzzhShWjh2DFStg6VI4fFi/5uEBQ4bobuitW6FnT2jbVidlIcRdy2v3crFKugBLl/amXLl/sHLaxhuBQwiKCGJat2kMazyMN/56g28CvqFexXp83/d7WlVvVSgxCFHsnDsHq1fDr7/Cpk2QlgaGkV3f18NDJ9+ZM3W3tBAiX0rkMpAA7dtPpUyZeA7v+JatT27jQa8HGbduHO3nt2eA9wDWP7GexLRE2nzXhvHrx5OYmmjukIUwP3d3XU5w3TqIiIAff4RHHoGyZfXxzKQ8bx4cPapr/3brBpMmwd9/Q5KMmRCiIFh8S1cpPRWxYcPs11auHI2j43dcuxZMnz6e/Bz8MxP+msBgn8F80PkDriZf5fUNrzN732zuq3gf3/X5jjY12hRIPEKUKCkpsH07/PGH3jLn/To765HP0dH6f0I7Oz1NackSfTwj49YjoyMjdZf2kSN6c3SE4cPh4Yf1EpdCFIH0jHRMVqYi+7wS09JdtEgxZMg25szJfq1790mkp9tx/PhEUlIMBngPIGhsEP9rpwsh/HvmX1LSU1j6yFKS05Jp+31b+izpw/az2830LYSwULa20KGDXuXqyBEIDdVdzG3aQEJC9rQjFxc9T3jDBrh2TY+O7tBBV0h69VXo3h2+/15fMy4OXngBli3T7w0Ohsce0+8F3bUtRCHIUBnM2D0D/2/8GbNmjLnDyZXFt3TPnFnCqVNDWLHiJZydP2byZFsMAzZunIzJ9A5BQdsYO7Z1jvd8vvNzJvw1AWsra15o/gJWhhXf7PuGqMQo2tZoyxtt3qCnV0/0bCghRK6SkuDff2HLFti8Gfbs0QnT2hrc3HRr99Il3Qr29obnnoORI/XrFy7oFbUMQ+9v2qSTtLU1vPUWrF2rzx0yBCpUMPc3FSXEhpMb6LaoGzZWNjjYOnBp/CVsTbZF8tklpqXr4TGAatXGMWDAF1Su3JHnnjtHaip06PAq8fFVMYzxXLyY84fDuJbjCH4umN739WbqtqnM2z+PiW0n8kWPLzhz5Qy9lvTCd7YvPxz8gdT0VDN9MyEsnL09dO2qyw1u3w4xMXrK0auv6oFXERG6JZyaqpPr/v26+/nMmeyEC7q126WLTrigW8lpaTpJV62qW8G//Wa+7ylKjG8DvqVimYosG7CM2KRY1p1YZ+6QbmLxLd1Mly79xOHDT3H1ahmcnZfRoUNH9u+fy5UrT7NhwwomTXok6//pG+0M38nUbVPp4dmD0f6juRR/iWErh3E8+jinY09To3wNXm31KiP8RuBk51SgMQtRosXF6WlH27frbfdu3fUMOpm2aqWrIzVrpgdluLjkfH9AgJ5TvHQpdOqk15kGWLxYt4rdi6SuiighIq5F4D7dneebP8+ULlOoOq0qPer2YHH/xUXy+SVyytC1a8EEBAzEx2caLi7dSUlJZ/36xqSkRPLLL98zfvyD+Pnd/hobT22k15JeJKUl4VLGBTuTHRfiL2Bvsqdfg34MazyMLnW6YG2VSwYXQtxaWpqeD7xjh07CO3bAqVPZx6tV08m3UaPsxwYN9H3l2FhwdYXTp/UcYgB/f13esHdvvbCHnZ15vpcoFqZtn8b4DeMJHBuIdyVvRv82msWHF3P5tcuUtSlb6J9fIpMuQEZGGlZW1qxbB9999zMTJ1YhMvIZrK2DWL9+GNbWn/Hmmy63HSR5Nfkqvx//nRVBK/jj+B8kpiUytNFQ1hxfQ0xSDBXLVGR44+EM9xuOb2XfQvkeQpQKFy/CgQM6GWeOZg4Kyp6CZBjg6ZmdiH18oEwZOHQI1qyBXddXmfvtN13a8K+/4MUXdav5xm30aN1trVR2t7YoVZ5d8yxHIo7w75P/ArDv/D52n9vNcL/hknQLwu7dF4iNrUNMTFWqVPmRSpV+5+LFKcTGVuSnn2YwduwjtGt35+vEp8Sz+fRmetfrTXJaMp0Xdmbb2W1Zx90d3RnqO5Tnmj+Hh5NHIX4jIUqJ9HQ4eVIn4MOH9RYYqFfQyizcYGurW7eenvpecNeu0KKFnsI0Y4Z+zNyiomDnTp20582DyZOhceOcm6envreckaE/H3SCzvz3r7i3oiMi9JSuU6fgoYegf3/dZV/cv1c+paSn3Hng1NWren66qWCnE5X4pAsQHLyDo0cH4uR0gZCQx2nadBAJCe9gGAFs2TKA2NivmTSpMuXL5/2aZ6+cZePpjfx5/E/WnVzHleQrWcf8qvjRvFpznvB9gtbVWxfpHDAhSrykJL0wR2aLOLN1fOZMzvPc3cHLS2916+qtdm29lGVAgJ66dPAghIRkJ/HISKhYUbeSv/oq5/WsrfVgMIBvvtExeHvrru8GDW6+F20pMjLg+HHdws/IgD599OC39et1YnF0hIUL9fzoEi4uOS7XMTmxSbH8FPgTj/o8Snllq6fDTZkCn30GTzxRoDGUiqQLEBkZxZ9/TsHNbQY2NjY88EAYp07NJjz8Xa5dc2Dx4s8ZMuQJ+vQx8t3rpJTiWNQxAi4EcObKGX479ltWK9jOZEcz92aM9BtJvwb9qGAv0x6EKBRxcXDihE4wmVvmfkREznPt7fXIag8PqFJF7yulV9+qWVO/LygouwvaMHSLZ8IEvT92LMyfrys3ZfL11UkcdPGIAwcgOVn/SEhO1i3plSv18YEDdZd6xYrZm5+fnhoF+vPd3MDpHgZtpqfrNbU/+ED/IAkLI0fLIjkZNm6EX36B117TSXn1al0Gsk8f/X3uu6/ETNWKTYql+mfVmdJ5Cs81fy7HsZ3hO2k1rxXzHYcxfNpfcP687jX56CNo2rRA4yg1STdTdPQFUlN3U7lyXz7+WBEf/wbNmm3C0XEvu3b1YNeu93j8cX8efvjuexVS0lP4KfAn5gbMZWf4TpLTkwEwMGhboy2danWii2cXWnq0lIFYQhSF2FidyM6c0Yt3hIdnb2fP6uUt/7sYR/nyOgH/d6taVSfqypV1yzg4WCdopXTyAnj+eZ3s7ex0Qrez093g/9ML8zB2rH5fVFT21qOHXvMa9LUvX9YrftWuDbVq6XvVTz6pj2/Zors+y5bV97bLltXxli2rv8ePP8KHH+pWfObnDh5MrlM3brRoEbz5pv4zyVSpkh645uCg52NHRupkXL26biWb6d74lCl6DF2XLnk7f+aemTz3x3PsfXovTavlTKRKKeq86UC98ETWnm6jf6i0b18IUZfCpHujFSuCqVDBl/R0a06fbkWdOnuwtY3n4MEH2Lr1Fbp06c3w4aZ7WpEuPSOd7We3M2ffHOxMdhy4dICACwEAmAwTdV3q0qVOF570e5ImVZvIQhxCmENGhk5ymS3CG7fQUP0YF3fz+xwddQLOTMRVq+oWauZWqVL283Llbp2glNLJ0sZGP1+xQn/u6dP6MTRUtz6nTNFd3La53I98/XWYOhX27dPZyNdXLzDSv3/+WhBK6WQdEqLvn4eHwxdf6GODBsHy5dnnli2ru9j37NH7c+fqBU+qVMn+/lWr6h8OBej4cZ33M8O981dSNPmmCQYGAaMDsv++//0XHnwQypVj4tzBfHJuORdevUClcm4FGu+NSnXSBYiPP8W//07Gzu4HUlLsiI/3wtk5GpMpnPDwuqxfPw5v7xGMHu1QYEVV/g79m4+2fsTe83uJSozKer1quao8WPdB3BzcsLW2xbuSN5XKVsK1rCsVy1SkmmM1ScpCmEtsrE7KFy/qxHKrx6tXc3+/nV12IrrT5uKiu3VzS5bp6fDPP3r5zcTE7EdfXz3nGWDbNv38Vute360rV3TGO3ZMd8FevKhjnDpVH+/Z8+ZazI0b66520NO6wsKyf4x4eOju28GD9fHoaP29c4s7PV3P9z5/nn+3WdFuxqMABM36mwZj2usfI3Pm6J6FMmX0Y0oK+PiwzzUV/2/9mRFUm7E70vTfU2bPxldfwfPPc+jSIRrPbszMnjN5ttmzBfvndoNSn3QzXbsWwp49X2IYm2nTZi9Hj/5OYOBEKlc+SVxcedate5YKFZ5n5Eh3PD0L7nPjkuJYeXQlPwf/jLWVNVtCtxCTFJPruVGvR+FSxoXPdnzG7vO78ankozc3HzydPWXAlhCWIClJ30O+fDl7u3E/IiLnlrlQyH8Zhk5ALi76nu+Nj+XL335zctKt0IJOunmRnKyX/bx8WXdFm0z6/ijobu6gIP29L17U3fpdumSvNFa9un7d3V13scfE6EQ9bZpOura2WYPeLtlWxz3lFK+33sqH2zrohF2x4s3xvPMOz/pfYsHBBZz/258KVWvr67u769HqXbuCyYRSioazGtKuRjtm9ZpVaH88knT/QymFYRjs3w/793eiTp3NZGQYGIYiI8OK3bt7EBb2JM2a9WLAAPt8jXjOiwyVweFLh9l4eiPbzmwj4EIAoVdCAX1PuKFbQ6ytrAm7EkZ0YnTW+6o7VefMy3r05tIjS0lMTcTdyR0PJw88nDxkFS0hLFVCgk5ONybiG6c55fYYF3fnflXD0PdhHR1117ajY/bm4HDzPeEbnzs46PvJNw70cnIq+Pu3SulWembpyDlzdEv47FmduJ2ddenIp57Sx//5h/C0KrjUd6Ns1fK8NM6gUSMYNQqdjKOi9I+epCR9XWtrqFGD8yqOvef30qden9uGE58STznbcgX7Hf9Dku5tKKUIDt7D7t0rKFduGa6uZ0hPt8NkSiY+3olt2/qTlvYEXbt2oHNnU0FP58oSmxTL7nO72XF2B9vDt7P3/N6shGsyTLg7ulO9fHWG+g7Fv5o/o34bxYGLB3Jco1PtTmwcthGASVsm4VrWlabVmtK4cmPK2JTJcywZKoMLVy/gZOeEo51jwX1JIUTeZWRAfLzu7s1tu3o1e4uPv/l5fHzOrunEPNQTN5nAxYXL1cozqk0U/ePcGXHNKzuB35jIHRx0Av/vltn1m/nc1lZvNjbZjybTbZN7v356unZISOGN4cpQGVgZhdNLIEk3j9LSFPv2BeDtbUVKSiSLF8+iYcNVWFllEBlZmR07HsfF5XF69bofX9/8TzvKD6UUYVfC2Ht+L/vO72PvBf2Y2S1tbVhzX8X7qFWhFm4ObjjYOtDQrSFj/HUJqwYzGnA08iigk3ZDt4Y8df9TvNDiBQBS01O5knyF41HHORZ1jGNRx+hbvy/N3Zuz6fQmOi/sjJ3Jjt71ejOk4RB6evXEzrp0Ta4XokRRSrcOM5NwfHx2y/qGVnZaVATNKyxnf5lYAN4MduW93eWwSkjU3eTXruVtZNPtGEZ2Ei5XLruVXq4cl2yr47FpAS/5bOTTLmvB3p4Ew4FD0e609IzU77Gzy07mtra8HLmIHhVb0L1ym5yjyTOf33AutrZM3PwWW89uzVqxqqBJ0r1LBw7s48yZF3Fy2k5Ghs6wVlaKs2frcvhwf+zsHqZ9+xa0a2eV60DDgqaU4nTsafae30vAhQD2X9xPwIUAIhMiAd01Xc+1Hk2qNsGvsh/VHKuRmpHKiegT7D2/l651uvJq61e5knSFih9XJF2lZ13bZJj4uufXjPEfQ1RCFMsCl3E08ijLApdx+dplytuVZ+eondR3rV/4X1QIC3Y1+So2Jhvsre9hyoOFW3ZkGU52Tqw8upJvA75lqO9QFjy8QA/yVErf0712TSfvzG7eG7cbX0tN1VtKys2Pmde5oYX+6YmHee3cOIIqtadB0n5ISmJM6pcs5nEuUZmy5GyxB1aChs/BtHXwyo68fb9prQ3Gd1Mc/64cdRPs9fShZ54psD8/Sbr36Nq1o5w8OZeIiPlYWV0hIaEt9vZbMZnSiI2tyLZt/bl27RFat+5Iz562RbpojVKKc1fP6SR8YT8BF/Xj2bjsOXhVy1WlcZXGNK7cGL8qftRwqsHvx3/Htawr91W8D6+KXtSuUBsbk81N10/LSGPjqY2sDlnNlw9+icnKxNStU4lKjKKnV08cbBywtrLG0c6Rui51AQiPCydDZWBrsqVS2Uoy+EuUCEopZu+dzSvrXyElPQVPZ0983Hx4r+N7NHRrSGJqIlaGFWdO25GerqfOFifxKfEEXAigXc3sNXOVUnyy/RNcy7oy8v6Reb5Whsrg7JWz1KxQM18xKKVnJzk76zoZmbZsVnTsZPDjd0k81jdBJ+zr28u7JjPj5BLOtV9FpYwyORcryXyemeSvb2dTIqhh/RXvJbbirav36wVTOnXKV6y3I0m3gGRkpHD1agDly7fk/PlY9u1riaNjSNa66snJdhw40IGwsCepUqUz/v6udOmS+3S7whaZEMmhS4c4cPEABy8d5ODFgwRFBJGaoZe4s7e2p4FrA3zcfPB29daPlbypXaH2HZPk06ufZv7B+aRlZC800LZG26yumhu7tq2trKlRvgZ96/VlevfpAPx69Fcq2FegVoVaVC1XtVC6rS/GX+T3Y7+zOXQz7o7uTO442eK7x9Mz0uUHigU7e+Us9WfU54EaD9DCvQWBEYEcuXyEnwf9jI+bD9/u+5YxS97DetEWej63kfmvDaK8fQGPwiwkiamJPPTjQ+wI38Hpl05TpVyVXM/74/gfeLl44VXRK9fjqempLD68mClbp5CWkcbR549iMky0mtcK38q+PNLgETrV7pTrD3zInn787bfXB05dl5GhpwF7e+ecrZSUloT7dHe61OnCsgHL8vWdH/j+AWISYzgy9ki+3pcXknQLSVJSOFeu/M3ZsxuJiVmHjc150tNtMJl0YouJqURYWH0CAztx9OgAnJy8mTPHCg8PPUre1laPRSgqKekpBEcEZyXhwIhAgiKCcrSK7a3tqe9aH+9K3ni7etOgUgMauDbA08Uzx+LhkQmRBFwIIDU9lbSMNCrYV6B9Lb26y8rglcQkxZCUlkR4XDihsaF4V/LmrXZvoZTC8SNHrqVmT6Eob1eeMf5jmNJlCkopXvjzBVzLuuLm4Ia7ozt1nOvg6eKZp+ogq0NW8/4/77PnvJ7IX9mhMrYmW8LGhWEYBq9veJ3wuHBaebSipUdL/Kr43fIfgMIUlRDFjD0zUErxTod3OB51nO6LuvN2+7cZ6ju0xCXfpLQkVh1dhbWVNf0a9Cu0ASyF4VjUMbxcvDAMgyOXj+BdyTvX+Hef3cegPhUID3Yn/Wk/qtaK44seXzDAe4BFz71PTkvm4WUPs+7EOhb2W8gTvrmvQ5yclozXV14kpCawavAq2tRok3UsMTWRefvn8cn2Tzhz5QyNKzfmzQfe5JEGj5CQmsAza55hzbE1xKfEU8G+An3r9eWF5i/ksmqUTrz16ulbvDf63//0uiHnzul1OQAWHVrE0JVD2TB0A13q5HHZqusyV686NOYQjSo3ytd770SSbhFJTj5PWloMaWlxHDy4jtTUKZhMyVnHMzKsOHKkI2FhkzlxoimBgccoU8YHf38r/P3J2vIyQjo1NRZra0cM497/cY5LjiM4IjgrCQdGBBJ4OTBHMra2ssbT2TMrCTdwbUCDSg2oV7FevkY4K6U4GXOS0NhQwmLDuBB/gcvXLtPSoyVDGg3hWso1an5eM8eCIgAT207kw84fEpccx4t/voins2dWIl57Yi3jWo6jvmt9fgn+hY+3fUzv+3rTu15vGrk1IkNlZCWxcWvHsSJoBeeungP0j4xHfR5l/sPzAdh0ehOVHSpT16VuobSMw2LDmL5jOnP3zyUhNYFHfR5lySNLOHL5CKN+G8Xuc7vxrezLx10+pnvd7gX++UXtYvxFpm6dysJDC7NG4zet2pRVg1fh7pS/wvRF3ROQoTKYunUq/7f5/1jYbyFDGg257flTpsDEibq4kZvvfoY+ewmfR5fy76vfW2zSTU1P5dEVj+p7t72/ZVSTUbc9/0T0CXou7igoVucAACAASURBVMmZK2dY8PACHm2oF69YGbyS/j/1p3X11vzvgf/xYN0Hb/rOSWlJrD+5np+Df2Z1yGrm9p7LI96PcCL6BBtObqB73e7Uca5zy88+elTXnJj48SkGD4vHt7IvwRHBDFw+kEPPHsr3D7nL1y4zY/cMnmn6TL7/W7wTSbpmlJx8gcuXl3Hu3Fri4/djMl3GMCAlxQZb21RSUuwIDW3Irl09OHCgB3/+6Y+bmz3z5kFERCINGhyiWrW9lC27l8TEwzRpshMrK2uOHh1FdPQfVKo0CDe3R3Fyalng/2PHp8RzNPIowRHB+jEymODIYE5En8jRtVzNsRr1XetTv2J96rvWp55rPeq71sfDyeOuWzRpGWlEJkRy9spZTsacpL5rffyq+HEs6hgdF3Tk/NXzWeeWsy3H/L7zecT7kTxf/+yVs+wI38GOszuoUq4KE9pOQCmFy8cuxCbFYmVYUce5DvVd6/NYw8cY0mgISilm7plJOdtyWZujnSM1y9fE3ckdpRTJ6cnYmexy/bv4dt+3jP1jLABDGg3htdav0dCtYdZxpRTLg5YzceNETsWc4iGvh1j92Opi1SoE3eq5dO0StSrU4mL8RTy/9KTXfb14usnTXIy/yKJDi1gzZA3WVtYkpSXdcUDS5WuXmRcwj9n7ZvPzoJ/xr+bPxlMbWXNsDZ1qd6J9rfa3nKOenpFOUEQQO8J34GzvzECfgQCMWj2K+q71aVO9DU2rNb2pBNzF+IsMXTmUv079xSCfQXzT65vbdhXv3g1t2ujVGJcu1Ws/eHkpOnROYc0qO85cOcPSI0t5ueXLZulZuZUFBxYwYtUIvuzxZdbMhjuJSoji4WUPs/XMVl5v/TpTu04lQ2XoggIerfL071BKegoGBjYmG77e/TUv/PkCHB6M47n+DB6/g94NO9K9bndsTbYopdh1bhfLA5ezZPNBLthvZIjvEBb3XwwUzbzb/JKka0FSU6OIidlCWNgmYmPXYTKdxsoqI+v4/v0dOHp0MGXKnKd37w8wmfQI45iYSkRF+TNs2AJsbSuxcuVqypSZj53dHxhGMjY2NfHweJaaNScU+ndISU/hZPRJgiODCYkM4WjUUf0YeTRH+cOyNmWp61JXb8518arolbVfzbHaPSWThNQETsecJjYpFv9q/gXSKlVKEXAhgJAo/V2ORh4lJCqEXl69+KDzBySkJuDw4c33A95s+yYfdP6AyIRIKn1SSQ8ss3XE0c4RR1tHxrcezwi/EQReDmRuwFxebvUyNcrXuGUcyWnJzNo7i+jEaCZ3nAzoHwn21vYkpSWRnJ5McloyNcrXwNHOkUvxlzh46SBVy1WltnPtAv8HKDU9lZT0FNJVOqnpqaRmpJKekZ7VOjh75SyRCZHEp8Tzc/DPLDy4kMZVGrN5+GZAj/bNrTckLjkOn5k+/H97dx4nV1kmevz3VlVXd/VevXf1Ur1kJSELe4QgoBcFERCURWTUYcRR1CiDuAzKBa/jFa+O4yAz4wKKuAAKiGAQDKCSYEiAQBLI0vtaXd3Vte/LuX+81dVpOksndHcSeL6fz/s5p6pPVZ8+1VVPvdvzXrnsSm45+5Ypq3MZhsHzA89z15a7ePC1B0mkE7yr9V18613f4tSGU/n+37/PVzZ8hVgqhlmZObXhVM5rOY+vv/Pr5Fvy+e6m7/JE5xNsHthMMKFTNl648EIe//DjBOIBTvqfk+j0dgK6teNUx6ncuOZGLl1yKX/u+jPXPHQNwXiQH1zwA65bfd0hA8m3vqVzPmzbNrlgzze/qdMiP/00bLV+h5v/fDPLqpfxPxf9z5Sm2dmUzqTp8nax3b2dMxrPwFHioNvbzZahLVjN1inlpPqTKMor4tmeZzm39dzD+j2xVIx169dhUqY3ndnJMAz2ju/lgvOKGRlNk7lhCalMkvEvjVNsLeacn53DX3r/gtVs5fz28/nQCR/i4sUXz8pqbol0gic6nmBx5WIWVy1+0883QYLuMSydjhEKvcjw8FMMDz9BMtmB1aqbVnUt+AS2bz+P7u4LMIwz+Nznijj9dFi9WudHLyryc+aZv+fcc3+DxbKEm276HoaR4Xvf+zdSqYXY7Ytobl7EwoVFOJ2HXoDkzTAMg5HwSC4A7xrbRYe3g47xDrq8XSTSidyxNouN9op2FlUuytWQJ2rJx2pmLcMwcsFlogQTQZxlThZXLSYQD/DDF35IMBEkGA/qbSLItSuu5dIlR76O6V96/sI5Pz9n2v3rr1nPexe8l4def4jLH5is5dcU1dBmb+PH7/8xy2uW0+vrpcfXg1IKV8iVK7e+81byLfncsfEOvv/37+ONeUln0qSNNBkjQ+KWBHnmPG54/Abu2nrXlN+db84ndksMgGsfvpb7Xr0PgDxTHpefcDnXn3T9IT/IPREPNz91M/dsu4cKWwW3nXMb1598PXnmPCLJCI7vOjAw+NjKj/GpUz81bbpaLBXj+f7n2dC9gQ3dGxgODtO9rhulFJf+5lJ6/b2saVyjS9Ma2u3tU4KnK+RiU/8mnut7jo39G/nCGV/gquVX8ftdv+dfn/5X7v/g/SyrWTbj18nvn7qqXjSqRzDb7bqf8o8df+Az6z9Dn7+Pq5ZfxdXLr85lTzqS2tpEcofXRl/j/236f2x3b2eneyfRlJ5Ss+kfN7GmaQ33vHwP//jo9JHHB+vLjMV66ej4PDU1V1NTc8VhndeRmGg6/va3Yd2NcXa4d+T6e+995V4UiosXX0xpfhmf+pTO7vi1r7353+uL+Xiy80kuWnTRjMaMzJQE3eOIYRhEox34/c/T17cRv38jVutOANJpMx0dq9i58x14PGswjFMpKWmnqkpRVASLFxtcfrkiFHqVF15YPaUGPTrawO7d3+WWW64kkfDx/e9voqzsdFpaKmlr06uZzeUo63QmTX+gn47xDvZ69urtuE7M0THeMWXO8L7N1YsqF9Fe0U6bvY3W8tbDyqz1VtHn7+ORXY9gVmbyLfnkm/PJt+Sztnkt9SX1eCIeXh97naHgEF3erly5+5K7aS5r5rubvstNT9005TktJgvd67ppLG3kwZ0P8qfOP2EvsGMxWTCbzJiVma+982tYTBae6nyKl10vY1Zm8sx55JnysJqtXHeSTtu3ZXALg8FBrGYrpzpOpbqo+rD+vpeHX+bGJ2/k2Z5naS5rpmed/oKwqX8TK2pXzDgYJdKJXDPxm802lMqkZrQk5yOPgMMBp522/5/ff7/O8/+Tn+gsh6FEiNuevY2fvPwTPr7q43zvPd8jmoxS+G+FVNoqabO30WZvo7msmYsWXcTZzrMZCAxw3aPXEYgHCMQD+GN+/HE/d114F9euvJatQ1u58JcXcmLtiZxYky21J7KqbhVWsxV/zM9gcJBEOpEr8VSc0xtPP+C1TaX8PPecrkm2t/87TU2fn3bMpk06p8WKFTO/rgdy883wve/pxY7q9j9wOufii/WXmL6+I1+ada5J0D3OJZNeAoG/Mzq6ieHhjWQymzGbIwCEQmXs2XMyu3efwtjYKRQVnUx7eyurV8dYtqyDdHo3w8O7CQT2UFLyCc455yw6O5+kv18P0unoWMnLL5/LK6+cxxVXnMfnPleE16ubyhYvhuXLoa1tbv+5E+kEXd6uXO14orw+9jqB+NSl1hwlDtrtOghPbJ3lztz0o7faqN/ZMBIa4dURPdCkrriOuuI67Db7MdVXbBgGj+5+lGd6nuH2c28/Zls79tXRoVucTjsN/vzn/acrNAydx/9jH4Oqqqk/S6aT5JnzCCVC3LXlrtyXpW5fN33+Pr5x7je4+cybGQ4Oc9kDl1GaX6qLVadnvXzp5ax1rs3lkn+z4nEXfX3for39DkymfNLpKK+//hHGxh6iqemLtLX9X1T2f+axx+Czn4UnntCfE29GMqnXQDj9dPj97w99/IMP6tUHn3pq5uvsplIBLJb5+5+SoPsWk8kkiUReIxjcyujoVjyerRjGK5hMeqpSIGBnz56T6ehYzejoKoqLV9HWtoiTTrJwyilQXR0iGHyJgYG/MT7+NOn0JkymGBbLNs46ayXPP7+NdetcDA+3YbEkKC5OsGBBinXrTuOcc2Bk5BV8vl4qKhT5+TVYrXXk5dViNs9uhp6J5txObydd3i46xzvp8mW33q7cCOQJE3OCnWVOHYjLWnCWO3O15IbShmMq0IjjVyIBZ52lV8B75RVoPnAX/XFhdPQR9uz5BOl0iBUrnqK8/CwADCPN3r2fY2joLtra7qC5+Yv86U+6trlihQ58BQV6/YIjDb5+P3z963rFwPfMYMB+LKZrw5dcAj//+dSfZTIJvN6ncLsfoKDASWvr7UQie9m6dTX19f+E0/kVrNbaIzvRwyBB920gk4kTDu8gGHyR8fGtjI1tJZPZicmk+1Hj8QK6u5fT0bGK0dFVFBSsor5+BcuWlXDiiTGqqzdTUbEWpUzs3v1Jhod/NOX5Uykrdnuck0+G9es/is1275Sfp9N2Vq8ep6ICurv/N5HIa1itddhsCyksXEJh4VIKChpn9W+OJqN66pG/N9dv2evXW2+4i3I1QksRvOKD14NgNVtpKW/RTXjlbbTaW3PNeW32tuOidnUwsZj+ABRz78tf1v2Pv/2tTmZ0KDt3wj//M9x776yv9f6mpFIhOju/wPDwTyguXs3Spb+kqGjplGMMw2B4+MfU1FzJX/9axvvep/uqN2zQKxBeey08+aReBnfh/nNmzLrrr4df/UovUlRUBF7vBlyuXzA29gjptB+zuQyH45OMjX2b9euHOOusr2Gx/AyTqYDGxnU0NX2RvLxZWjx9PyTovk3pGvEuQqFteL3bcLu3kUxuw2KZXC5wYGABHR2r6O1dSSq1irKyVSxcWM7y5c/T3DxKWZkVk8mKUlYqK98LwJ49XWzc6KOjI8XwsBufb4RUKsl//uc/43TCo4+uI53+EyUlQ1gseuRoILCMiy/WmV8efPCbdHRkcLsXY7E4qK8vo6mphg9+sPaIFpFIJMaANFZrLZHIbl555d3E4wNTjhksuJ5Xg+V0+bJNeN7uaWsaV9oqJwNx+WQwbrW30lTadExN9QCdsvanP4UbbtCDdk45RQeAW289OlnQDsYwDMLhHUCGoqIVh9UcahgGweALDA7exdjYQxQXr2LJkp9jsx14TucbpVJ+PJ7HGRt7mLq663L/y4crGu1m69Zv8OMft1Fe/k/84AeH6IDMGhjQNcH3vQ8eeOCIfvWc2LHjcsbGHqa5+Uu0tNyGyXTgf5y9e+H00yN8/vM3cf31t1FXp/vud+/Wtf7iYti4Ufdxg84lkEyOYbO1H/D1drv10rvvfOf05vlYrJeCAp1GcnT0YUZHHyCTSZDJxPH5EoyMJDj77MeprS1i166PMzr6MFVVl1JTcwV+/7v56let3L9Pkqo//GEPbW234nb/BoulhjVrejCb52aMiARdkWMYBvH4AKHQNny+V3C5thGNbiMvrzN3jN9fSUfHKrq6TsTjWYbVegJVVSeweHE5y5fDsmWT0yJAp2jr6dHf4JWCO++E//xP2LvXoLx8hAULdlFYmGDDhvMxm+HRR8+gtHTzlPPasuVivvhF3aHz6KNLSKfjGEY5JpMNyBCNvo+rr9bDFR9//BSSySSQIS8vQFFRH+PjX+ayy75FOh3hmWc+QSJxClbrKRQXL6Cs7GEWLvw4FosNl+sXxOP91NdfTzhtzvWhTQTiiaDc4+uZMhfZpEw0ljbSUt6iS1kLrfbW3O2GkoY5D8rh8GsUFDgxmYp44AG46Sb9Yf7003DqqbBuHdx9N5x0Etx3nx4NOsHv30gw+BJ2+3kUFp4wr8kaIpHdbNv2LhKJbEKSglaqqy/H4bgBm63loI8Nh3fx+uvXEAq9hNlcQlXVpUSje1m58mnMZhsjI78klQpQXX05VmvNlMcmkz5GRx9gdPQhfL6nMYwkBQWtnHLKK1gsJQQCm7HZFpOXN7OpJzrPfx9bt55MKjWGUnnZv+PTlJWddchrevvt+gvRX/8Ka9fO6Fce5FzSgOmIXsdUKsjQUIof/cjOJZfsZOFCD+XlZx/ycYYB//Vfm1i27F0UFDSxYsWfsNl0tf3FF+H97/dwwQWPsW7dJmKxjUQiegDoihVPUFHxHjKZJEpZppzzt7+tWw327NG15FQqxOjog7hc9+D3/42TT36JkpLVDA7+kIGB/8BkykepiYpAPiee+CgWSymJxCgWSykmUz6JhG7uDwT0e2TdOti8WadWLiiAO+54lY0bt6DUdVx2Gaxd+yAtLbObNUyCrjikVCpAOLydUGgbo6PbGB/fBuzEZJpc0WN01EFPzzJ6e0/A51tGfv5SqqsXs3BhFcuWKU44Qa+BPSGdBpNp/wNM0ukIkcgekslRIhE/fn81y5bpNJL33fcvjI2Nkkr5gBhgYnj4fL773RsB+O//vpxAIINhmEgkbOzdu5JU6t386lerAVi0SH8r39fFF+tBGhNN54ZRQEHBNSxevA67/cTsuSbxel9m+/ZRQqERvKE+wrFBOocX4ykpI93wFwKBPWzdWcpAag/YxiAvCkqv8FRfUk9zWTNNpU1Tt2VNNJQ0UF1UPaMRsRM1u9HR35JOR1i0SKeL3LSplmTSg9u9lJdeOoVI5GSuuOJczjpLJ9jIZJI89th27r9/My0tm1m7djOnnnonlZXvwuNZz/btFwKQl1eL3X4e5eXnUVNzJRbL7KyZbBgGkcguxsf/iMfzR8rKzqS19XYymQS7dn0Uu/1/AQajo7/D6/0zJ520mZKS1YTDO0kmvZSVvQOlTEQiu0kkRikvP4tUKsSrr76H2tprqa29Ztq5bt9+KR7P7wEzdvu5VFVdRnn5OykqOoFotJPNmxdQUNBOdfUHqKr6QDaJjIlMJs7f/96KYaRpb7+D2tprc4OEpv5NGVyue9m168988Yu/4Cc/UaxYkSAW62Fo6L9xue4hlQpwxhm9h+w+iUR0bbemBrZs0e+Nw5HJpPB6/8zIyH2MjT1Mfn4TLS23Ult79YweHwwa7Np1P8nkv1Baej6nn34PkYj+AvD5z+s+0v0NmHzxRZ2ScdEifdvv38j27e/HZMrH4bgBu/1cysrO5Omnt2AynUYsVo7DsYbS0neQl2enru46zOYCurv/N273b6ipuYLq6g9hsy3nhBMUNTWwYcMIXV1fwe1+gEwmjM22kLq6j1Nff920L1OT10N/gVm6VDdzP/AAXH21vq5PPKEHgTbu5yV54QX9pfShh8Bme5kvfOE2Pv3pR2b6MsyIBF1xRAwjQyzWQzj8GuHwTkZHX8Pv3wm8nhs9DRAMljMwsIj+/kUEg4swmxdl5wcvZNGiYhYvnj5yc/bPdTK4d3frwRkT6393duqBF1dcAakULFnyGhdf/APOP/9eCgqi3Hff16isvJ3/83+8bNw4dYmoRMLKnXf+B2vW/DPr1u3hhRf0aJGxsXqGh9twjbTy52c+Rv3Zfprf8Suqw6/h2bUEwxzCZIlizovxyEsn0mn/O1WNr3NGqYPo8JmQV0V+fg21FeU0VJSzuLWElrIghfHniAWeJBHvR6k8Kivfz7JlvwUMxsYe4zvfeZHa2q2sXLkVi8VNY+ONLFjwXSKR3WzduopMRs+dDYer6e8/nSuu+BIVFXpQTDTajc/3DF7v0/h8T5NIjHDmmR7y8srxeB4nFuvFZLJhMuVjMuVjNpdSUfG/AIhE9pJK+Ukmx0gm3SQSI5jNhTQ03ADoZkq//28kk6MAFBUtp77+ehob95/lSKcxLUMpxe7d1zM8/GPS6TrC4TZKSzdRVLSaU099aQavu0E4vB23+37c7vuJxTqprv4gy5Y9mD3v3dhsi/ZbiwkGX2bv3hsIBJ6ntPQdLFz4Q0pKVuV+HghsYfv2z5JMbmbnzjO488713HlnOe961+RzpNMR/P7nqKg4H4CdO68kL6+KmporKSo6cVq/4S9/CR/5iO6PvHoGsXLfkcm7dv0TLtdPsVjsVFV9gGBwC0VFKzjhhPuyx2b2+8WhsxN+/vNdVFZ+hpUrN1BcfBKLFv0XhnEad98NP/iBbqlqaYE//nFqC8m2bXDuuXqhgeeem3yPhcM7efXV9xKPD9DSchstLV8nk0myfv0eWlqWsmzZ9PNwu3/L0NB/4fM9C2QYHFzCT396Kx/72FVcc02YzZsXUVFxAfX1H6e09B2HrHl2dOja8ZVXwssv69ry+vXw3hn2HGQysHUrRCJRzjlndpuZJeiKWaWDcS+RyOuEw3sYGdmD37+HdHoP+fn9U451uZrp6VnGyMgyksllFBQso6ZmKQsX6mDc3q7XmZ5PoZB+g+7ePU44/DNCoSaWLv0Q55+fYWzscbZvr6a0tJqKimoqKkrIz1cYBuTl+Rga+iM7d3aRSnUBXeTldfHCC//B2Wd/gNWr/8a2be8hGs0jnbaQSuny7W/fw4pLFavf8SOWq9/mziOdNjE+Xsctt/yePSffxj+c/xjXNJnYsvkC/rrpIl7Ydi7JTDG2wjRXfWUDa88oIjO8nNOWNtDqKCUen2iubSSTSdLV9WVKS0+jpOR08vOdBIOKsjLdb/a3v00d8JNOGyQSPdhsrbjd0Nl5KfH41Pka+fmNrFmjX89XX72A8fEnpvy8qOhETj31VQC6uv6VRGKE0tLTqKi4gIKCpgNe/1RKL59qt+uBMGvWBGlpeZyzz/4dTU27eeaZqzjzzOv41KdqCYX063WouZsw2W9sNhdN6+/NZOD553XtZsUK+OhH9Qjk11/PUFHxc/r6vkQy6eGUU14hP99BZ+cXcbnuxuOp4957v82aNR9h3ToTtoN8NhtGml27rsPt/g2GoXOuW631NDR8FqfzKxiGgd//Ao8+upQrryzFMPR51NVBfT3U16eprw+wZEmciooxxsZ+x8jIL1m+/FGKipYQCGwhHh+ksvICTKZ8DCNDOh3CYiklGNzGa69didP5VWpqrsFksvDCC/CNb0A4fD9f+cq1ZDKFFBX9G+94xycx7TO1Lp3WrUC/+IVOYZmfr7ssYjH4h3+AwkJdo2xpmfr3ZjJxUqkAVuv0edmGoa/1Bz6g9zduhKEhPWc5Hh/hs599mLVrH6Cubpx3v3sbSumavGkGLUH7OuMM3XS8ZAl85zu6z/xYSHMtQVfMm3Q6QjTaQSi0h6GhXYyPv0YyuROrdRdm82RGKpfLSU/PMnp6lhMMLsNkWo7dvoS2tkIWLoQFC3Qf8bE2IOhwGYb+8DKbwWyO4PF00t09QCw2QDLZTyrVT7/rZlpWQrpoBy9uj7L+d214A3H8oRShUIZIBJLn3QjVu3LPW2mrpL2iXS/8kF38oaGkITcPt7KwMjc96ktfgjvugNpavbxoJKKbC8fG9HNddhk88kgGu32EvLw4Vmuc9vY4f/gDFBev4KtfBZ9vM9XVI2QyVWQyNdTU1PK5zxWjlOK++2B0FPLydHBLJPRgmg9n1we44w4YHtb3d3To4Hf55XDPPfr6fPKTer7r2rU609CGDfrDtLFRNwNee63++QUX6FrMihVTMz8dSCajn+uhh3QSC5dL/z/ddx986EO6Frd6tX5tVq70cvHFv8YwPsVVV4Xwek+ko+MKtmy5hVtuKaVm/y2c+5VMeggENhMO7yQc3kF5+bnU13+MRGKETZv0tweLpYJMJk0sFueee77Db37zGVpadnDPPftmiFJs23YOv/71Hbjdp1BcrF+3r34VLroIduyAL3xBfympqnqeD37w0zid28hk2lm69F/ZvPlSPvlJO5/97CDve99tLFv2jRlNlzEM3Qy+d69+Hf/yF/1+PBxPPqmn/7zznXqglcul+1l7enRQTKf1dT9Q7Xymtm/XU7auvFL//x0rJOiKoy6TSRGLdREO72R8fCdu906i0Z1YLLtz05oyGcXwcBvd3cuzfcfLSaWWUFbWTktLKYsW6eakRYv0ZPrD7RM7noUSITrHO+n0dua2HeMddHo76fP3kTEyU443KzO1xbXUFddRU9DA+LPXkHC1UVpsxV6aT21FPjd9KUVdcR0vPl/CUHb9CK9Xl7w8HawBPv1pXdPxeifXAV++XNdeQI+afvHFqee7dq1+DOjA1t2tn9Ph0CNdL7xQ10oOpbNT99WtX68zIKWzics8Ht2Pd//9ummxrU2X1lYdhFau1MHD6YTxcf37LrtMbyfGHYyPw5/+pKfz7Niht52d+ne9+92xWZ93nk5H8Ho3EA7vIB7vzw0Iqqy8mLy8sxgcHMflupeKinyqqgpJJN7FD3/YSDCo/6ZgUJebbtJfPnbuhE98glwwLi42WLToUdauvZ1M5iWKi09h+fIXKCg4/Krf8LBuAr/kksMPuKCv/Ze/rAdVXnih/pJz4YX6XN8OJOiKY1YmkyIa7SAc3kE4vBOvdwfB4E4ymT0oNZka0u+vZGionaGhNoaG2hkba8NkaqekpI3a2gba2025D16n89j61jvXEukEff4+hoPDU3Iru0IuXGEXI6GR3BKK+47InlCUV0RdcV1uIFhzaXNuAFhzmd4vyy87YB9bNDoZjE0mXZu0Wme/28Dn07Wuri498EcpuPFG/cGeTE4eV1OjmzLNZh1M29s5aLPwviIRnZ/8eG5hMQyD8fH1JJMeams/PCvLfx75uRwbzb3zTYKuOO5kMnEikT1EIruJxbqIRjvx+7uIRDoxjL4pATmRsOJyteaC8vBwO6lUG/n57ZSXt+J0FtLaSq5UV789PwgyRgZPxDM9MIdcDIeGGQwO0u/vZyAwQDKTnPLYEmsJTWVNOEoc1BfX61IyfXs0llhLp/XC5l1dukbd2KinhxyreXnFW58EXfGWkskkicf7iUY7s6ULr7eTcLiLTKYTkyk45fjx8VpGRpy4XC24XC14vU6gBZuthYoKJ83NRbS0kCvl5W/PoDwhY2QYCY3Q5++bWgK6Nj0c0jXqfVeN0925GQAAEz9JREFUmlBeUJ5Lw+ksc07dL3dSXVh9zC7oLsRskaAr3jYMwyCZ9BCL6WAcjXYSCvXi9/cQj/cAfbk+5Ak+XxXDw62MjLQwPNyKz9cCtGKztWC3O2lutuF06oDsdOq+xLd73DAMg/HoOMOh4VwgHgoO0e/v12k5s6k5J9aynWA1W3VT9j415P3dri2undGcZiGORRJ0hcgyjAyJhItYrJdYrIdYrAe/X5dEohuleqcF5bGxegYHFzA0tIDBwQV4PAswjAXYbAtwOEpxOnW/4UQpmZ1cE8c9wzDwxXy5ANzr72UwMKgDdba2PBwcxhP1THusQlFVWEV9yWRQnrI9yk3aQhyMBF0hZmgyKHcTi/UQjfbg93cSCHSSTO7FZBqecrzPV8PAQDsjI05GRpy43c3EYs3YbM3Y7c00NZXR3q5obtbTYRwOnaBdTEqkE5N9y9nBYLmgvE9wdoVc0/qaAYqtxVP7lovraShtoKGkAUeJg4ZSvZ3NRcqFOBgJukLMknQ6nO1H7siWvQSDnUQifaTT/Sg1tZYcDpfgdjczMtKcC8rBYDPgxGptprTUgcNhobFRz2OcKKXH94JHc2J/Tdq57RuauSPJyLTHlxeU4yhx0FTaREt5C63lrbTaW3PbSlul9DeLWSFBV4h5oGvJbuLxPmKxPuLxPsLhXrzeXmKxfjKZXszmqU2pmYyJsbEGXC5nLji73c2Ew81YLM0UFTVTV1dGc7Oem9zYqLcNDcf3tJa5ZBgGgXiAoeAQg8FBvQ3o7VBoiD5/H93e7mnN2sXWYlrL9SIWdcV11BTVUFtUS01Rjd4v1vsVtgpZl1kclARdIY4R6XSYWKyfeLyXWKwv27fcSzDYTzTah2H0o9TUubSRSEm2ptzM6GhTbptMNmO1NlFc3IjDkZ9rvp7YOhxSYz6YYDxIt6+bbm/3lG2vv5eR0AijkdFpSUdAJx6pLqqmtqg2N+irtihbJhKSFNVQaauksrCSAosscvx2I0FXiOOEYaRJJEaIx/tzteVYrI9wuI9QqJ9ksg+lRqc9zuutZXS0gdHRBsbGdPF4HIRCDZjNDRQUNFBVVU5jo8rVmCdqzVVVMhp7fybmNbvDbkbCI3obGpncD4/kbo+ERoin4/t9nmJrMZW2SqoKq6gqrKKysJLqwuppo7brS+qlifstQoKuEG8h6XSUeHyAeLx/SnCORIYIhwdJpQaBsWmPi8WKcLmcuFzO3MCvkREn4+NOzGYnpaX1tLVNZvaaKJWVEpQPZaJJeyIAj0ZGGYuMTSmeqCe37w67CSVC054nz5RHXXEdjhIHrfZWFtgXsLByIQsqFrCgYoHMcz5OSNAV4m0mk4kTjw+RSAwRjw9mSx/RaC+hUC/xeC8wtU8znbbg89Xhdtfj8TjwePQ2HHZgtdZTXOwgP7+ZkhI7lZWKykpypapqcl9iwsyEEqEpo7X3HRQ2GBiky9tFr793ShN3ibUkF4DtBXZMyoRJmTCbzJP7Su8X5hXSWNpIQ2mD3pY0UF5QLkF7HkjQFUJMk0qFss3Xul85Hu8nkRjO1piHSCaHMZmm15jD4ZIpNeWJ4nI5CQQaKCmppanJitPJlKQiTqfub5b0jDOXSCfo8fXQMd4xrQQTQTJGhnQmTcbI6H1jcj+Wik17vlwgLtGBuKm0iaayptz2UHm2xcxI0BVCHJFMJk4i4SIeH8rVlmOxXkKhHiKRXpLJXsA37XHhcCUeTz1udx3j43WMj9dntw7S6Sby8hopKXHgcOTR0ECuOBw6N7bd/vZaRWouJNIJhoPDDAQGGAwO6m1gkIGg3vYH+hkMDJI20lMeV2wtzgXh6sJq7AV27DY79gI7FbaK3L7dZtfLSEo/9DQSdIUQcyaVCuRqy4nEEImEK1uGiUZdRKPDpNMulJo60CiTUfh8dYyMNDI62sToaCNud1N2v4lksgmzuZ6KCgtVVeRKfb0eBDYRqOvq9MpA4vClM2lcIRf9gX76/f30B/rp8/fRH9ALX4xFxvBGvfhiPgz2Hx+K8opoKW+ZVpxlTprKmqi0VZJnfhst+4UEXSHEUWYYBqmUL9vHPJCdNtVPPD5AJNJPJDJAMtmPUlMHF2UyZoJBBx5PEy5XE/39zdkR2g48HgdjYw683noqKgpyQXhiZPZEmbi/UBJSHbGMkcEf8+ONeRmPjuONenOJSnp8PfT4euj199Lj68EXm97yUZpfmptCte+2qrAKR4kj19TdWNpIWUHZUfgLZ5cEXSHEMU8HZn9uVLYemT2x35fdH8Awpk/NicUqCQR0EB4cbGRgYOq8Zre7iZKSAhobdRN2fb2uIe9bJu4rLpbBYG+GL+bL5dru9/fjiXrwRDx6u+9+xIM/7p/2+BJrCY2ljbkyEYwbSxtpKssG5mO831mCrhDiLUEH5vFcH7OuOQ/tsx0kHh8gkXBNe2wsVoPf34THU4/XW4bHU0YwWEo4XEYkUko4rPdTqXIymRZstgZqa03U108G5Iltc7OsNjUbJvqdJ5qzBwIDek3n4OS+K+Sa1rRdbC3OBeKaohoKLYUU5hViy7NRmJfdt+j9Ymtxbi60o8SBLc8253/XTIPuIXtFlFJ3AxcBbsMwls/GyQkhxEwppcjLqyQvr5Li4hMPeJyeMjXRjD2ZlnOiBp1O7ySVCpBK+YHUfp8jlbIyNtbKwEA7fX3tvPRSG0ND7QwNtTM62ojZXEJLi8qtw9zaOrkms8Oh12XOz5+Di/AWYjVb9XrL5c4DHpNMJxkODetgPBGYs0G6P9BP53gn0VSUaDJKJBnZ76IY+5rIwT1R6ovruWTxJaxpWjPbf94hzWQows+AO4F75/ZUhBDiyJlM+dhs7dhs7Qc9zjAMMpkY6bQOwDoQe7IrTHVSV9fJggVdRKN/I52eujZwKlVEMFiPx1PP8HA9HR0OXnihPje/eXS0gXDYQX5+KeXlekR2ebkulZW61jyRrnOilJdL7fmN8sx5NJc101zWPKPjU5lULgBHU1EC8QCukEvn3s6WiYUxnu15luHgMM4y57EZdA3D+KtSqmXuT0UIIeaeUgqz2YbZbMNqrT3gcYZhkEx6iMU6iUa7ck3bicQw8fgwicTLxON/JJOZnmUqmSwmFHLg9zvweBpwux0MDdWzZ4+dUMhOMKhLKFROMmnHbi/C4VBTplLtO0jM4ZAa9MFYTBZK8ksoyZ9c2HpF7YoDHj8x1/lokEH3QgixH0oprNYqrNYqSktPP+BxqVQwG4gns4FNZgUbIpHYSDw+hGEkDvgc6XQesVg5oVA5Pl85gUA5u3aVs3Wrvi8UKscwyoEWzOYVVFY24HSqKUlI7HapMc+USZkwmY/OpPBZC7pKqeuB6wGam2fWJCCEEMc7i6UEi6WEwsJFBzxmYvpUKuUllfKSTHqn3J64L532k0z6iMd9xOP9pFI+DMOPyRSd8nyBQAWdnSvYsGEFXV0r6OhYydjYMurqbLkm7InBYG+8XVQ011dEHMyMRi9nm5cfm+lAKhm9LIQQsyeTiZNMeolGOwiHXyEUehWf7xWi0e1ABADDMBEINBMIVDM+Xo3bXcX4eDV+fxV+/8S2ikSiAqu1ApvNTkWFlaoqnRGsulonImlpgfZ2XXuWBCQzN2ujl4UQQhxdJlM++fl15OfXUV5+Vu5+w8gQjXblAnE02kkyOUYyOUIyuYNEYgzDiBzweePxIkKhCgIBOz5fBS5XBa+9VpdNQNKAxeKgpKSB6moHTmc5CxYoamt1/3JBwf630sR9cDOZMvRr4BygSik1ANxqGMZP5/rEhBBCHJxSJgoLF1BYuIDq6sv3e0w6HckG4tHsdjzbnD1OKjW5n0h4icV2kUw+C4xPe55YzIbH46Cz04HXW4fHM5Fbe+p+Ol2N02mmvZ1cWbBAb5ubpfYsyTGEEEJMkU5Hs4PD9KCwWGyQQGAIr3eQRGIYcKHUMCZTYNpjdRrPRtxuJ319zQwN6RWp3O5mxsacFBQ0UVlZRE0NuVJbO3W/rEyn8CwqOn5WqJLmZSGEEEfEbLZhs7Vhs7Ud9Lh0OrLPYheuXKCOxfpobu5j+fK/Eo8PAlOn58TjJQQCNYyP1zA6WkNnZy1bt9bg8+ni9dbg91fh81UTjVZhs1lyQbiwUPc9L1wIixZNbltaIO84WGNBgq4QQogjYjYXHjI4ZzKpbG25j3i8l1isj2TSTSIxQiLhJpHoIh5/nnR6DMjs9zkSCTuxWBWRSDWhUDUeTzV9fTU891wNjz1WjddbQzBYQ2lpDfX1VbS3W6irm6xB19ZO7h/t+c4SdIUQQswZk8lCQUEzBQXNwFkHPM4w0tm+5ZFs//Nori86kRjd574uEom/k0yO8cYa9IRAoAKfr4pAoIpt26pyI7f16O1qTKYqLrtsBR/+8PxPb5WgK4QQ4qhTyozVWo3VWj2j4w0jQyrlzQZkdzY4u7O16FFisTEikTHi8V7S6ReBUUymyQQlicT3gXVz88cchARdIYQQxx2lTLmFMGDJIY83DIN0OpStPY+Rn98w9ye5HxJ0hRBCvOUppXLZw2y21qN2Hkcn+aQQQgjxNiRBVwghhJgnEnSFEEKIeSJBVwghhJgnEnSFEEKIeSJBVwghhJgnEnSFEEKIeSJBVwghhJgnEnSFEEKIeSJBVwghhJgnEnSFEEKIeSJBVwghhJgnEnSFEEKIeSJBVwghhJgnEnSFEEKIeSJBVwghhJgnEnSFEEKIeSJBVwghhJgnEnSFEEKIeSJBVwghhJgnEnSFEEKIeSJBVwghhJgnEnSFEEKIeSJBVwghhJgnEnSFEEKIeSJBVwghhJgnEnSFEEKIeSJBVwghhJgnEnSFEEKIeSJBVwghhJgnEnSFEEKIeSJBVwghhJgnEnSFEEKIeSJBVwghhJgnEnSFEEKIeSJBVwghhJgnEnSFEEKIeSJBVwghhJgnEnSFEEKIeSJBVwghhJgnEnSFEEKIeSJBVwghhJgnEnSFEEKIeSJBVwghhJgnEnSFEEKIeSJBVwghhJgnEnSFEEKIeSJBVwghhJgnEnSFEEKIeSJBVwghhJgnMwq6Sqn3KqV2K6U6lFJfnuuTEkIIId6KDhl0lVJm4IfABcAJwNVKqRPm+sSEEEKIt5qZ1HRPAzoMw+gyDCMB/Aa4ZG5PSwghhHjrmUnQbQD697k9kL1PCCGEEIfBMoNj1H7uM6YdpNT1wPXZmyGl1O43c2JvUAWMzeLzvZ3JtZw9ci1nh1zH2SPXcvYc7rV0zuSgmQTdAaBpn9uNwNAbDzIM40fAj2Z0aodJKbXVMIxT5uK5327kWs4euZazQ67j7JFrOXvm6lrOpHl5C7BQKdWqlLICVwGPzvaJCCGEEG91h6zpGoaRUkp9BvgTYAbuNgxj55yfmRBCCPEWM5PmZQzD+CPwxzk+l4OZk2brtym5lrNHruXskOs4e+Razp656S41jGljooQQQggxByQNpBBCCDFPjumgK+knj5xS6m6llFsptWOf+yqUUk8ppfZmt/ajeY7HC6VUk1LqGaXU60qpnUqpddn75XoeJqVUgVLqBaXUK9lreVv2/lal1Obstbw/O2hTHIJSyqyUelkp9Vj2tlzHI6CU6lFKbVdKbVNKbc3eNyfv72M26Er6yTftZ8B733Dfl4ENhmEsBDZkb4tDSwH/YhjGUuAM4Ibs/6Jcz8MXB84zDGMlsAp4r1LqDODbwL9nr6UXuO4onuPxZB3w+j635ToeuXMNw1i1zzShOXl/H7NBF0k/+aYYhvFXYPwNd18C/Dy7/3Pg0nk9qeOUYRjDhmG8lN0Poj/kGpDredgMLZS9mZctBnAe8Nvs/XItZ0Ap1Qi8D/hJ9rZCruNsmpP397EcdCX95OyrNQxjGHQgAWqO8vkcd5RSLcBqYDNyPY9Itkl0G+AGngI6AZ9hGKnsIfJen5nvAzcDmeztSuQ6HikDeFIp9WI2uyLM0ft7RlOGjpIZpZ8UYr4opYqB3wGfNwwjoCsW4nAZhpEGVimlyoGHgaX7O2x+z+r4opS6CHAbhvGiUuqcibv3c6hcx5k50zCMIaVUDfCUUmrXXP2iY7mmO6P0k+KwjCil6gGyW/dRPp/jhlIqDx1wf2kYxkPZu+V6vgmGYfiAZ9H95OVKqYlKgLzXD+1M4GKlVA+66+08dM1XruMRMAxjKLt1o78InsYcvb+P5aAr6Sdn36PAR7P7HwV+fxTP5biR7Sv7KfC6YRjf2+dHcj0Pk1KqOlvDRSllA96N7iN/Bvhg9jC5lodgGMZXDMNoNAyjBf3Z+LRhGNcg1/GwKaWKlFIlE/vA+cAO5uj9fUwnx1BKXYj+9jaRfvKbR/mUjhtKqV8D56BXyhgBbgUeAR4AmoE+4EOGYbxxsJV4A6XUWcDfgO1M9p99Fd2vK9fzMCilVqAHpZjRX/ofMAzjdqVUG7rGVgG8DHzEMIz40TvT40e2efkmwzAukut4+LLX7OHsTQvwK8MwvqmUqmQO3t/HdNAVQggh3kqO5eZlIYQQ4i1Fgq4QQggxTyToCiGEEPNEgq4QQggxTyToCiGEEPNEgq4QQggxTyToCiGEEPNEgq4QQggxT/4/9ZfpfSKi/Q4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"k\"]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.ylim([0, 5])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
